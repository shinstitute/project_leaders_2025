---
- "\uFEFFSubmission": strack103s1
  Status: Accept
  Name1: Erik
  Name2: Boman
  Email1: egboman@sandia.gov
  Institution: Sandia National Laboratories
  Title: Novel preconditioners to speed up linear solvers
  Field: Applied mathematics, computer science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing
  Abstract: The most expensive part of many simulations is the linear solves. Preconditioners
    are critical to accelerate iterative solvers for large, sparse problems. We will
    develop and implement algebraic preconditioners that can be used as a black-box
    for a wide variety of matrices. We propose a new variation of incomplete factorizations.
    An initial implementation may be done in Matlab or Python, but the eventual goal
    is to do a parallel implementation and study its performance. If good results
    are obtained, a research publication is a strong possibility. The software may
    potentially become part of the Trilinos framework, and thus accessible to thousands
    of researchers world-wide.
  Desired: Numerical linear algebra, computer programming, familiar with version control
    (e.g., git/github), some experience with GPU and/or parallel programming desired.
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only; Permanent
    Resident OK
  Comments2: 3.0 GPA minimum
- "\uFEFFSubmission": strack104s1
  Status: Accept
  Name1: Ravi
  Name2: Patel
  Email1: rgpatel@sandia.gov
  Institution: Sandia National Laboratories
  Title: Uncertainty quantification for operator learning under physics informed constraints
  Field: Scientifc Machine Learning
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); Machine Learning
    and AI
  Abstract: One promising strategy in scientific machine learning seeks to obtain
    a PDE description of a physical system by inferring the PDEâ€™s operators directly
    from observations of the system. Ideally, a modeler would also enforce a priori
    known physics constraints such as conservation and symmetries to guarantee the
    model is at least physically valid. However, observational data is always noisy
    and sparse, so learned operators are only useful insofar as their uncertainties
    have been properly quantified. Without these measures, an analyst using the models
    cannot determine in which regimes the model is valid. The staff members have previously
    developed methods for learning uncertainty aware operators. The intern will focus
    on combining these operators with physics informed constraints and studying the
    interaction. While the methods developed will be broadly applicable, we will focus
    on two exemplars, crack propagation of a composite under shear loading and climate
    forcing under volcanic eruption. This topic will blend together ideas from a variety
    of subjects, e.g., PDEs, statistics, machine learning, solid mechanics, and climatology.
  Desired: "(Not necessarily required) familiarity with coding, machine learning,
    Bayesian inference, PDEs, and HPC"
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack105s1
  Status: Accept
  Name1: Stefan
  Name2: Wild
  Email1: wild@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Learning while optimizing
  Field: Numerical optimization and learning
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); Machine Learning
    and AI
  Abstract: Our research addresses mathematical optimization of challenging computational
    science problems. We will be exploring ways that we can use machine learning on
    the data generated internally by an optimization algorithm in order to improve
    its performance on a chosen application.
  Desired: Desire to collaborate, basic algorithm knowledge and experience in a programming
    language.
  Special: International OK
- "\uFEFFSubmission": strack106s1
  Status: Accept
  Name1: Sri Hari Krishna
  Name2: Narayanan
  Email1: snarayan@mcs.anl.gov
  Institution: Argonne National Laboratory
  Title: AI-Based Adjoints to Diagnose the Sensitivity of Ocean Models to Parameters
  Field: AI, Machine Learning, Earth Sciences
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing;
    Machine Learning and AI
  Abstract: We are interested in understanding the sensitivities of an ocean model's
    output, to the model parameters. Estimating this sensitivity is very time consuming
    by brute force. Alternatively, adjoints have shown great promise in uncovering
    sensitivity of the model to its parameters. Yet adjoints are very time consuming
    to develop manually and very involved to develop via automatic differentiation
    (AD) for some models. Because neural networks implemented in machine learning
    frameworks can be differentiated trivially, we have want to explore how to generate
    an accurate neural network (NN) surrogate for an ocean model. We then use our
    NN model to generate adjoint versions of the original model.
  Desired: Experience in ML frameworks, models.
  Comments1: The project can be tailored to individual interests and expertise
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack107s1
  Status: Pre-Match+Workshop
  Name1: Andy
  Name2: Nonaka
  Email1: AJNonaka@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Multiphysics and Multiscale Modeling with AMReX
  Field: Modeling and Simulation
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing;
    Machine Learning and AI
  Abstract: The Center for Computational Sciences (CCSE) and Engineering at LBL is
    home to applied mathematicians, computer scientists, and domain scientists that
    perform modeling and simulation of complex PDE systems across a variety applications.
    We are seeking collaboration with scientists interested in working on existing
    CCSE projects and/or developing their models and algorithms using the AMReX framework,
    an exascale ready infrastructure that supports structured grid, particle/particle-mesh,
    and machine learning algorithms. Active applications in CCSE include astrophysics,
    cosmology, multiphase flow, accelerators, plasma physics, microelectronics, atmospheric
    flows, oceanic flows, microscale flow, and stochastic mesoscale systems.
  Desired: Numerical analysis, numerical ODEs and PDEs, C++, python, parallel programming,
    GPU programming, domain science expertise.
  Special: In-Person Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack108s1
  Status: Accept
  Name1: Lingda
  Name2: Li
  Email1: lli@bnl.gov
  Institution: Brookhaven National Laboratory
  Title: Building a Program Database to Facilitate Machine Learning-based Computing
    Research
  Field: Computer Science
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Machine Learning and AI
  Abstract: Machine learning (ML) has shown great success in many domains, and increasing
    efforts are applying ML in the field of computer science and engineering, for
    instance, to design more efficient hardware and software. Due to its data driven
    nature, it requires thousands if not millions of programs to generate training
    data in ML techniques, and the computing research community does not have such
    a collection of programs in hand. Particularly, traditional benchmarks are short
    in number, and source code hosting websites (e.g., GitHub) have abundant code
    snippets instead of executable programs. This project aims to bridge this gap
    by creating a database including a large number of executable programs. The main
    task of this project is to collect/write programs that stretch both computing
    power and memory capability of modern computers, leveraging coding exercise websites
    such as LeetCode and CodeForces. This database will subsequently be used for program
    performance predictive model training and testing. Besides the main purpose mentioned
    above, this project will also help students sharp their programming skills and
    benefit their future careers in both academia and industry, giving the fact that
    these coding exercise websites are the de facto means to prepare technical interviews.
  Desired: Major in computer science/engineering or related fields; proficiency at
    one or more compilable programming languages (e.g., C/C++); knowledgeable or interest
    to learn about computer hardware/architecture.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack110s1
  Status: Accept
  Name1: Benjamin M.
  Name2: Feinberg
  Email1: bfeinbe@sandia.gov
  Institution: Sandia National Laboratories
  Title: Software and System Architectures for Analog Linear Algebra Accelerators
  Field: Computer Systems
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Machine Learning and AI; National Security
  Abstract: Analog computing has significant potential to enable new applications
    on autonomous systems by providing order-of-magnitude improvements in computational
    efficiency. Unfortunately, most of the work on analog hardware has focused on
    device and circuit optimization rather than flexible and programmable systems.
    To remedy this issue, this project will develop components of a system software
    toolchain including tools to effectively map applications to the target hardware
    and manage other runtime components. Additionally, this project will use Sandia's
    Structural Simulation toolkit to evaluate the developed software on a simulated
    system and evaluate potential architectural optimizations. As part of this evaluation,
    we will consider trade offs between programmability and system-level performance
    and efficiency for a variety of applications. This project will involve interdisciplinary
    collaboration with both application and circuit/device experts to ensure that
    the developed toolchain is useful for application developers and provide feedback
    on architectural challenges that could be mitigated at the circuit or device level.
  Desired: "-Experience with C/C++ -Basic knowledge of computer architecture, compilers,
    or programming models -Interest in novel computing concepts"
  Comments1: The project described above has numerous individual components which
    can be tailored to specific skills and interests of the SRP participant. I do
    not expect an SRP participant have knowledge or interest in all aspects of this
    project.
  Special: Minimum GPA (specify what GPA in comments below); other
  Other: Neither US Citizen or In-Person are required but both are strongly preferred
  Comments2: Center Requires a 3.0 GPA
- "\uFEFFSubmission": strack111s1
  Status: Accept
  Name1: Emil
  Name2: Constantinescu
  Email1: emconsta@anl.gov
  Institution: Argonne National Laboratory
  Title: Physics-based machine learning and uncertainty quantification
  Field: ML, PDEs, numerical simulation, uncertainty quantification
  Topics: Machine Learning and AI
  Abstract: This project aims to advance computational science by integrating numerical
    methods for solving partial differential equations (PDEs) with machine learning
    and statistics for uncertainty quantification. Traditional simulation models have
    limitations in capturing complex behaviors inherent in systems like weather forecasting,
    climate modeling, power grid management, and nuclear physics. By incorporating
    machine learning algorithms into the numerical solving of PDEs, we aspire to build
    more accurate and efficient simulation models. Additionally, we will employ statistical
    methods for uncertainty quantification to provide more reliable predictions and
    to understand the range of possible outcomes. The ultimate goal is to develop
    a unified computational framework that is versatile enough for applications in
    various disciplines, from predicting severe weather events to optimizing power
    grid operations and advancing our understanding of nuclear physics phenomena.
    We want to explore new approaches to modeling complex systems, offering more accurate
    and reliable predictions for scientific inquiry and practical applications.
  Desired: Machine Learning, Python, Numerical simulation of PDEs, uncertainty quantification
  Special: In-Person Only
- "\uFEFFSubmission": strack112s1
  Status: Pre-Match+Workshop
  Name1: Steven
  Name2: Hofmeyr
  Email1: shofmeyr@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Extreme-scale metagenomics
  Field: HPC, bioinformatics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing; Machine Learning and AI
  Abstract: I am looking for students interested in working on metagenomics, especially
    large-scale metagenome assembly, and machine learning for metagenomics. Here at
    LBL we have consistently done the largest ever metagenome assemblies, and are
    working on improving our code base, as well as researching new algorithms and
    approaches, such as with AI/ML.
  Desired: Familiarity with HPC systems, competence with C++ and python. Bioinformatics
    and AI/ML knowledge is a plus
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack113s1
  Status: Pre-Match+Workshop
  Name1: Jose M.
  Name2: Monsalve Diaz
  Email1: jmonsalvediaz@anl.gov
  Institution: Argonne National Laboratory
  Title: A learning experience of compilers, runtime systems and parallel programmin
  Field: Compilers, Runtimes, Parallel programming, OpenMP, LLVM, HPC
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software)
  Abstract: High-Performance Computing is an exciting field that constantly pushes
    the limits of computation. HPC is a complex field. Not only is it necessary to
    have scientific knowledge of the applications, but also to have a deep understanding
    of how systems work. The more knowledge of the systems and tools, the higher the
    scientific impact could be. In this project, we seek to allow learning about compilers,
    runtime systems, and parallel programming. We aim to find a project that considers
    the needs of the current projects at ANL in addition to the professional development
    of the participants. We plan on using parallel programming models such as OpenMP,
    SYCL, OpenACC, and others. We explore innovation in their runtime systems and
    compilers. We will use the LLVM compiler infrastructure as one of the most important
    compilers in the area of HPC. By the end, we would like to encourage participants
    to 1) be part of the LLVM community, 2) better understand compilers, runtime systems,
    and parallel programming, 3) get involved in the area of HPC, and 4) create the
    necessary grounds for professional development.
  Desired: 'The following is a list of topics we could work on. It is not a checklist
    of requirements, but a list of topics we can use to start the discussion. - Programming
    languages:  - C, C++ or Fortran  - Python - Parallel programming:  - Threading
    libraries  - OpenMP, OpenACC, SYCL, or similar  - MPI, RPC, or similar - Understanding
    of parallel programming concepts - Understanding of compilers:  - User-level understanding
    (e.g., compiler flags)  - CS level understanding (e.g., compilation pipeline and
    compiler stages)  - Developer-level understanding (e.g., LLVM development) - HPC:  -
    Cluster infrastructure  - HPC network interconnects  - HPC applications'
  Special: International OK
- "\uFEFFSubmission": strack114s1
  Status: Accept
  Name1: Destinee
  Name2: Morrow
  Email1: dmorrow@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Using Machine Learning for Early Detection of Obstructive Sleep Apnea
  Field: AI in Healthcare
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); High-Performance
    Computing; Machine Learning and AI
  Abstract: Obstructive sleep apnea (OSA) affects 24% of all Veterans or 1 in every
    15 Americans and is associated with increased risk for developing cardiovascular
    and metabolic comorbidities such as heart disease, stroke, hypertension, and type
    2 diabetes mellitus. A vast number of patients are already experiencing at least
    one of these comorbidities by the time they are diagnosed with OSA; suggesting
    that OSA is being diagnosed well after the onset. OSA shares many symptoms with
    other diagnoses such as depression, increasing the diagnosis gap. With the use
    of machine learning and natural language processing, we can better understand
    and identify OSA and target patients for treatment closer to the onset, reducing
    the likelihood of patients developing comorbidities.
  Desired: python, pytorch, mpi, dask, R, clinical data, big data, electronic health
    records, high-performance computing, natural language processing, large language
    models, machine learning, predictive modeling
  Comments1: Remote work only.
  Special: other
  Other: Remote work only
- "\uFEFFSubmission": strack116s1
  Status: Accept
  Name1: Oksana
  Name2: Guba
  Email1: onguba@sandia.gov
  Institution: Sandia National Laboratories
  Title: Improving vertical discretizations in atmospheric modeling
  Field: Numerical methods, atmospheric modeling
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: Due to the specifics of the flow in atmospheric global circulation models,
    horizontal and vertical dimensions are discretised very differently. The atmospheric
    dynamical core in the climate model that we use is formulated for hybrid pressure-based
    vertical levels. There are a few research questions that are related to the vertical
    discretizations in our model. For example, while having more vertical levels is
    better for model's fidelity, their number is restricted by related computational
    cost. Therefore there is a question of how and where to place a limited number
    of vertical levels while increasing the model's fidelity and usability for applications.
    The project can be focused on a few relevant aspects, including developing numerical
    methods, evaluation of the model for climate applications, or uncertainty quantification.
  Desired: The project would be tailored to the participant's interests and background,
    assuming it is relatively connected to the atmospheric modeling.
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only; Permanent
    Resident OK
  Comments2: Min GPA 3.0
- "\uFEFFSubmission": strack118s1
  Status: Accept
  Name1: Drew
  Name2: Paine
  Email1: pained@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Understanding Scientific User Needs
  Field: User Experience (UX), Computer Supported Cooperative Work (CSCW), Human Computer
    Interaction (HCI)
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); High-Performance Computing
  Abstract: User Experience (UX) research &amp; design is the practice of investigating
    the real world needs of humans and designing solutions to improve their ability
    to use computational systems. UX work at LBNL investigates the needs of scientific
    users (e.g., Jupyter users at NERSC, scientists at the ALS) and designs software
    to enable them to more efficiently and effectively do their research. Conducting
    UX work provides teams with the opportunity to diversify their points of view
    and dig into the challenges their focal users face on a daily basis, building
    empathy and reframing the software production process. UX also impacts the sustainability
    of software by improving the likelihood that it will develop a user base who are
    vital to its continued existence.
  Desired: qualitative research experience is ideal research question / hypothesis
    development
  Special: other
  Other: virtual is great
  Comments2: I am remote and will be virtual only.
- "\uFEFFSubmission": strack119s1
  Status: Pre-Match+Workshop
  Name1: Doru Thom
  Name2: Popovici
  Email1: dtpopovici@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Hardware Software Co-Design
  Field: Computer Science
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: The hardware landscape is constantly changing to match the needs of scientific
    applications. CPUs have provided much of the compute power, however recently the
    focus has shifted towards highly parallel GPUs and specialized units customized
    for specific operations like matrix multiply or Fourier transforms. As such, library
    and framework developers need to be always active to adapt the software but also
    keen on offering information to hardware developers for better hardware support.
    Moving forward, more emphasis should be put on hardware-software co-design, namely
    developing strategies to optimize certain algorithms, creating models to guide
    the optimizations and the hardware itself, and then automating the process by
    using high level frameworks like JAX or others. This becomes even more critical
    nowadays when computation is applied on data that exhibits dynamic and sparse
    behavior. This additional dimension makes the search space for efficient algorithms
    and hardware harder. Therefore, the work I am doing is looking into ways to reduce
    the search space and offer solutions for various scientific applications in a
    short amount of time, whether those solutions are all in software or whether some
    components make use of specialized hardware.
  Desired: C/C++ background, a little bit of GPU programming, enthusiasm to get hands
    dirty and benchmark algorithms and systems
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack120s1
  Status: Accept
  Name1: Kristofer
  Name2: Bouchard
  Email1: kebouchard@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Foundation model for proteins
  Field: AI and biology
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.)
  Abstract: Foundation models are massive (&gt;1B parameters) deep networks that have
    been pre-trained on large and diverse data sets and can then be transfer-learned
    to other relevant tasks. Salient examples include GPT-4, DALL-E2, etc., While
    this class of models has been impactful in industrial applications, foundation
    models for science are nascent. Proteins are fundamental units of biological processes.
    This project will build of diverse extent work across LBL to create a foundation
    model that integrates all known protein structure and sequences. This protein
    foundation model could then be used as the basis for, e.g., generating novel protein
    sequences with enhanced functionality, inferring atomic structure from SAXS data,
    or inferring the function of newly discovered proteins.
  Desired: pytorch, large-language models, transformers, graph neural networks,
  Special: other
  Other: none
- "\uFEFFSubmission": strack122s1
  Status: Accept
  Name1: Massimiliano
  Name2: Lupo Pasini
  Email1: lupopasinim@ornl.gov
  Institution: Oak Ridge National Laboratory
  Title: Surrogate models for materials science
  Field: Artificial Intelligence for Materials Science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing; Machine Learning and AI
  Abstract: Material design and discovery are crucial for the US Department of Energy
    (DOE) in order to advance energy technologies, improving efficiency, and addressing
    sustainability and environmental challenges. Exploring the space characterized
    by different materials is extremely complex due to the myriad of possibilities
    to mix different natural elements at different percentages. Such exploration is
    impractical given traditional technologies. In fact, laboratory experiments are
    labor-intensive, and physics computational models require massive computational
    resources. Both experimental and computational approaches preclude an effective
    (fast and thorough) exploration of several materials. Artificial Intelligence
    (AI) and Machine Learning (ML) enable an effective exploration of a several materials
    within a fraction of the time required by traditional experimental and computational
    methodologies. This internship offers the opportunity to become acquainted with
    the scientific challenges that the US-DOE is facing to achieve materials design
    and discovery, and appreciate the advantages that AI and ML can provide to this
    field.
  Desired: The applicant should desirably be familiar with basic AI and ML concepts.
    Familiarity with Python packages for ML (e.g., Scikit-Learn and PyTorch) is desired,
    but not required.
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only; U.S.
    Citizen Only; Permanent Resident OK; International OK
  Comments2: '3'
- "\uFEFFSubmission": strack123s1
  Status: Accept
  Name1: Qiulan
  Name2: Huang
  Email1: qhuang@bnl.gov
  Institution: Brookhaven National Laboratory
  Title: Data Popularity and Data placement Optimization for big data Analysis
  Field: Large scale storage systems, storage optimization and data analytics
  Topics: Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); Machine Learning and AI
  Abstract: Scientific experiments and computations, especially those in NP &amp;
    HEP programs, are generating and accumulating data at an unprecedented rate. Big
    data provides opportunities for new scientific discoveries. Nevertheless, for
    the Scientific Data and Computing Center , managing the vast amount of data cost-effectively
    while enabling efficient data analysis in a large-scale, multi-tiered storage
    architecture is a real challenge. The topic revolves around the exploration and
    development of techniques aimed at comprehending data popularity and optimizing
    data access. Through studying data access patterns, doing data analytics, we can
    identify frequently accessed datasets, prioritize their availability and subsequently
    design a policy engine to enhance resource allocation for analytical tasks. This
    research topic assumes critical importance in today's data-driven world, as it
    holds the potential to significantly improve data analysis efficiency, enhance
    decision-making processes, and fuel innovation across a diverse range of domains.
  Desired: High-performance storage system(dCache, Lustre), big data analytics, AI/prediction
    modeling, monitoring tools like ELK, Python, C/C++, Java, Linux
  Special: Minimum GPA (specify what GPA in comments below); International OK
  Comments2: '3.5'
- "\uFEFFSubmission": strack124s1
  Status: Accept
  Name1: George
  Name2: Michelogiannakis
  Email1: mixelogj13@yahoo.co.uk
  Institution: Lawrence Berkeley National Laboratory
  Title: Computer architecture, system profiling, and networking
  Field: Computer architecture, networking, data analysis
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: The umbrella of my research is high performance computing (supercomputers)
    as well as applications. The task broadly is to design the supercomputers for
    10-20 years from now. There are a few potential topics that look for adjacent
    skills. One possibility is research on computer architecture that uses knowledge
    of hardware description languages or FPGAs. Another possibility is networking
    (either on-chip or system-wide) research on new router architectures, flow control
    and such by the use of a simulator. Another possibility is profiling production
    systems by the use of perf or similar tools followed by analyzing and creating
    new metrics and plotting results in order to extract insights. Other related topics
    are also possible such as programming models, algorithms, and job scheduling.
    A combination of the above topics is also possible and encouraged. In addition,
    if faculty or students propose interesting and related topics that will also be
    great because it can lead to new areas of research.
  Desired: 'A subset of the following: Computer architecture, hardware description
    languages, data analysis with python or similar, profiling systems, network knowledge,
    use of simulators for networks.'
  Comments1: Exploring new topics is encouraged. The aforementioned research topics
    include machine learning techniques in multiple levels so such an experience is
    desired. Applying for external funding opportunities is encouraged to make sure
    that does not become a constraint. Also, unfortunately I'm on travel during the
    workshop dates. I'll try my best to attend what I can.
  Special: Permanent Resident OK; International OK
  Comments2: No requirements from the above
- "\uFEFFSubmission": strack125s1
  Status: Accept
  Name1: Julien
  Name2: Loiseau
  Email1: jloiseau@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Co-Design Summer School 2024
  Field: HPC
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing
  Abstract: 'The CDSS 2023 subject will focus on modeling radiation hydrodynamics
    using the FleCSI framework. This work can be decomposed in two steps: the radiative
    transfer library and the hydrodynamics code. The hydrodynamics part will feature
    a mesh based implementation for our test, either Lagrangian or Eulerian. In the
    radiation library implementation, we will use flux limited diffusion as a starting
    point. Multiple different approaches can then be explored for better treatment
    of the radiation energy, such as the multigroup method. This base code will enable
    us to run interesting simulations including Lowrie radiating shock, Su-Olson Marshak
    wave, and ablation problems. The complexification of supercomputers, in both number
    of nodes and on-node hybridization, forces us to rethink our approach to high
    performance computing. In this context, task-based parallelism provides a promising
    path forward. The summer school proposes to use the FleCSI framework as a base
    for the simulations. FleCSI is a compile time configurable framework from LANL
    which supports the development of multiphysics applications. LANL is funding a
    next generation exascale supercomputer called Venado. The aim for the summer school
    is to run the simulations at scale on Venado, taking advantage of the NVIDIA superchip.'
  Desired: 'Computer Scientists: HPC, Kokkos/CUDA/HIP, MPI. Applied Mathematicians:
    Iterative and Multigrid Methods. Preconditioners. Physicists: Hydrodynamics, Radiative
    Transfer (diffusion, multigroup etc), Shock Physics.'
  Special: In-Person Only; U.S. Citizen Only; Permanent Resident OK; other
  Other: Graduate Students
- "\uFEFFSubmission": strack127s1
  Status: Accept
  Name1: Ajeeta
  Name2: Khatiwada
  Email1: ajeeta@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Application of Machine Learning in Nuclear Data Evaluation
  Field: Nuclear Physics
  Topics: Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); Machine Learning and AI
  Abstract: Nuclear Data libraries, which contain information about the interaction
    of particles with nuclei, are carefully curated from experimental data and theoretical
    predictions. This data includes details about nuclear reactions, such as their
    reaction probability (cross section), decay yields, spectra of the outgoing particles
    etc. and are used to understand/predict the behavior of particles in nuclear systems,
    such as nuclear reactors, astrophysical processes, radiography, gamma-based interrogation
    techniques etc. As such, any inaccuracies and imprecision in the nuclear data
    gets propagated to the uncertainties in the application of interest. Until recently,
    most general purpose nuclear data libraries have utilized Bayesian approach to
    tune the theory model input parameters to fit the experimental data. In this project,
    the student(s) will explore machine learning based approach to combine the theoretical
    models with experimental data to come up with evaluated nuclear data for specific
    reaction channels and physics observables. Upon the successful completion of this
    work, the work will be published in peer reviewed journals.
  Desired: "* Hard working * Friendly * Team player * Preference to someone with background
    in physics and/or math * Familiarity with coding (preference to Python) * Familiarity
    with/interest in Machine Learning algorithms"
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only; U.S.
    Citizen Only
  Comments2: GPA&gt;3.25
- "\uFEFFSubmission": strack128s1
  Status: Accept
  Name1: Alina
  Name2: Kononov
  Email1: akonono@sandia.gov
  Institution: Sandia National Laboratories
  Title: Quantum Dynamics Simulations
  Field: Computational Physics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Quantum Computing and Information
    Science
  Abstract: Quantum dynamical simulations can predict important properties like opacity
    and conductivity that govern how materials interact with light and electric fields.
    In addition to materials engineering applications like solar cells, these properties
    determine the behavior of fusion energy experiments. State-of-the-art simulation
    techniques for computing these properties are run on supercomputers and still
    require many physical and numerical approximations that degrade accuracy in favor
    of feasibility. Someday, quantum computers may allow more efficient and precise
    calculations, but requisite algorithms are still being developed and analyzed.
    This project will characterize the numerical behavior of dynamical simulations
    of model systems and help inform methodological improvements and limitations for
    both classical and quantum computers, or explore another relevant aspect of mutual
    interest.
  Desired: Proficiency with Python (or another programming language) and familiarity
    with undergraduate-level quantum physics will be helpful. Interest in dynamical
    systems, quantum computing, materials science, plasma physics, or related areas
    is desirable.
  Special: Minimum GPA (specify what GPA in comments below); Permanent Resident OK
  Comments2: 3.0 GPA
- "\uFEFFSubmission": strack129s1
  Status: Accept
  Name1: Xingfu
  Name2: Wu
  Email1: xingfu.wu@anl.gov
  Institution: Argonne National Laboratory
  Title: Autotuning Scientific Applications at Scale
  Field: HPC, ML
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing; Machine
    Learning and AI
  Abstract: As we enter the exascale computing era, efficiently utilizing power and
    optimizing the performance of scientific software under power and energy constraints
    are challenging. Scientific software developers often rely on HPC systems with
    the default configurations setup by the vendors to run their applications, however,
    their applications are not efficiently executed with the default system configurations.
    The number of tunable parameters that HPC users can configure at the system and
    software levels has increased significantly because of the complexity of the HPC
    ecosystems, resulting in a dramatically increased parameter space. Attempting
    to evaluate many (or all) possible parameter combinations becomes very time-consuming.
    Therefore, scientific application developers will be able to use our publicly
    available autotuning software package ytopt (https://github.com/ytopt-team/ytopt)
    to autotune their applications on the target HPC systems to identify the best
    configuration (for software and system parameters) and then use the best configuration
    to run their applications efficiently on the target systems. This approach not
    only optimizes scientific software for efficient execution and energy efficiency
    but also saves considerable energy on exascale supercomputers at DOE leadership
    computing facilities.
  Desired: 'Desired relevant skills: python and any programming language (C, or Fortran,
    C++) Bonus: Some scientific application needs fine-tune on HPC systems'
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only
  Comments2: '3.5'
- "\uFEFFSubmission": strack130s1
  Status: Accept
  Name1: Nathan
  Name2: Urban
  Email1: nurban@bnl.gov
  Institution: Brookhaven National Laboratory
  Title: Neural partial differential equations
  Field: Applied mathematics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); High-Performance
    Computing; Machine Learning and AI
  Abstract: Numerical computer simulation models are used to predict the behavior
    of physical systems such as fluids or materials. These simulations are based on
    underlying partial differential equations (PDEs). Neural partial differential
    equations (NPDEs) are a machine learning (ML) approach that replaces these physical
    governing equations with a neural network. This ML approach is used when the equations
    describing a systemâ€™s behavior are not fully understood from a physical perspective,
    because it permits (1) learning unknown governing equations from data, and (2)
    quantifying uncertainties in the mathematical form of learned equations. "Hybrid"
    simulations are also possible, with some of the equations specified from physical
    principles and others learned from data as neural networks. In this project, we
    will explore the potential for NPDEs to describe various physical systems, such
    as the heat diffusion equation, or more complex systems like the reaction-diffusion
    equations describing spatially-distributed chemical reactions, or the Cahn-Hilliard
    equations describing phase separation in self-assembling nanomaterials. This can
    include studying the ability of the neural network to emulate the behavior of
    the original system, as well as Bayesian statistical and mathematical dimension
    reduction methods to efficiently quantify uncertainties of the NPDE in a reduced-dimensional
    space of neural network parameters.
  Desired: Scientific programming Mathematics (ideally at the level of differential
    equations, linear algebra, or multivariate calculus)
  Special: In-Person Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack131s1
  Status: Accept
  Name1: Liwen
  Name2: Wan
  Email1: wan6@llnl.gov
  Institution: Lawrence Livermore National Laboratory
  Title: Multiscale modeling of electrochemical interfaces
  Field: Materials Science, Chemistry, Chemical Engineering, Mechanical Engineering
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing;
    Machine Learning and AI
  Abstract: This project aims to understand degradation at the electrolyte-electrode
    interfaces during cell preparation and electrochemical cycling. We will leverage
    various computational methods developed at LLNL to address how degradation precursors
    are formed during initial chemical or electrochemical reactions and how these
    precursors dynamically evolve to form an inhomogeneous solid electrolyte interphase
    (SEI). In addition to the understanding of SEI formation, we will elucidate the
    implication of SEI formation to ion transport kinetics and address the impact
    of microstructural features of the SEI.
  Desired: Familiarity with Linux operating system and high-performance computing
    environment, Fundamental knowledge of general chemistry, thermodynamics, kinetics
    and computational materials science, Basics of data analysis, Fundamentals of
    electrochemistry
  Special: Minimum GPA (specify what GPA in comments below); Permanent Resident OK;
    International OK
  Comments2: 'Minimum GPA: 3.5'
- "\uFEFFSubmission": strack132s1
  Status: Accept
  Name1: Khaled
  Name2: Ibrahim
  Email1: kzibrahim@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: HPC Workflows Performance Modeling and Tuning
  Field: Performance Modeling, tuning, and Optimization
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing; Machine
    Learning and AI
  Abstract: In the performance and algorithms group, we tackle various applications
    and workflow performance optimization problems, using refactoring techniques of
    these codes to leverage DOE supercomputing machines efficiently. We aim to enable
    the development of cutting-edge solutions to tackle computationally challenging
    problems. Our SRP visitors are expected to engage in ongoing research efforts
    within our group to engage in an experience in developing performance modeling
    and tuning methods. We also encourage application developers with performance
    challenges to engage with us to apply our developed methods in improving the performance
    of their code in leading DOE computational environments. We also encourage application
    developers with performance challenge to engage with us to apply our developed
    methods in improving the performance of their code in leading DOE computational
    environments.
  Desired: Skills in performance modeling, profiling, and tuning. Familiarity with
    HPC programming models and/or with DL and ML frameworks.
  Special: In-Person Only
- "\uFEFFSubmission": strack134s1
  Status: Accept
  Name1: Erik
  Name2: Palmer
  Email1: epalmer@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Supercomputer User Ticket Modeling and Analysis for Improving Scientific
    Output
  Field: Data Science/Applied Math/HPC
  Topics: Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing; Machine Learning and AI
  Abstract: At the National Energy Research Scientific Computing Center (NERSC), we
    cater to a user base exceeding 9,000 individuals, facilitating groundbreaking
    scientific endeavors on the 8th fastest supercomputer globally. As part of our
    support team, our primary mission is to assist scientists and researchers in using
    this powerful resource for a variety of scientific computation. Our responsibilities
    encompass troubleshooting application issues, optimizing performance, and maintaining
    the computing hardware and software environment. In order to do this, we would
    like to make data-informed decisions based on user behavior by analyzing support
    ticket content to identify and address user needs strategically. For this project,
    we would like to use our ticket text information to gain insight into user behavior,
    sentiments and needs regarding high performance computing. We are open to working
    with a variety of tools and techniques to meet this goal. This could include machine
    learning driven analysis techniques such as natural language processing and data
    clustering powered by our own supercomputer. Or it could involve simple statistical
    analysis techniques as these models can also be effective tools for aiding understanding.
    A successful project will produce data artifacts that help identify user trends
    or behaviors to guide decisions about user services.
  Desired: We would like students who value listening skills, exhibit perseverance
    by working alone or reaching out for help from others. Students who regularly
    and proactively check-in for assistance and progress updates are also highly desired.
    Knowledge of coding, statistics, machine learning, and language processing are
    useful, but not required as mentees will be given time, resources and our guidance
    to learn. The project mentors would like to use Python as the primary language,
    so familiarity with Python is ideal. We believe there is a lot of room to move
    in different directions with this project depending on your own interests.
  Special: Permanent Resident OK; International OK
  Comments2: I believe we can accommodate most US-based students.
- "\uFEFFSubmission": strack135s1
  Status: Accept
  Name1: Kathryn
  Name2: Maupin
  Email1: kmaupin@sandia.gov
  Institution: Sandia National Laboratories
  Title: Enhancing model productivity through model form error quantification
  Field: Computational modeling, uncertainty quantification
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Machine Learning and AI
  Abstract: Despite continuing advances in statistical inversion and modeling, model
    inadequacy due to model form error remains a concern in all areas of mathematical
    modeling. The Bayesian paradigm naturally integrates uncertainties from both experimental
    data and model formulation, including initial or boundary conditions, model form,
    and parameter and numerical approximation. While model improvement is an enterprise
    that is continuously enabled by the availability of cost-effective high-performance
    computing infrastructure, model error is unavoidable in many situations. This
    problem is attributed to the incomplete understanding of the underlying physics,
    likely in addition to large and poorly characterized uncertainties in calibration
    and validation data. Introducing a model discrepancy term into the Bayesian framework
    can improve the predictive power of a given model and, arguably, the transferability
    of physical parameters. Much like physical models, calibrating a discrepancy model
    requires careful consideration regarding formulation, parameter estimation, and
    uncertainty quantification, each of which is often problem-specific. This project
    seeks to explore methods for model form error quantification that can be easily
    generalized for wide applicability. Of particular interest are methods that may
    enable physics discovery and enhance extrapolation.
  Desired: 'Desired interests: Surrogate modeling and computational modeling Desired
    skills: Proficiency in at least one programming language (preferably C, R, or
    python) Relevant skills: Machine learning or surrogate/reduced order modeling
    methods'
  Special: other
  Other: N/A
- "\uFEFFSubmission": strack137s1
  Status: Accept
  Name1: Sarah
  Name2: Poon
  Email1: sspoon@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: 'User Interfaces for BRaVE: National Biopreparedness and Response Capabilities'
  Field: User experience (UX) design and research and frontend engineering for science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization)
  Abstract: The BRaVE initiative, which is developing countermeasure against emerging
    biological treats, needs user interfaces and data dashboards to enable scientists
    developing diagnostics, vaccines, and therapeutics, to make sense of their data
    and make decisions for which pathways to pursue. This project will focus on trying
    to make scientific data accessible, understandable, and actionable, as part of
    the effort to be prepared for the next pandemic.
  Desired: 'Interest in: web development (javascript, html/css, etc), user experience
    design and research, information visualization, data dashboards'
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack138s1
  Status: Accept
  Name1: Davis
  Name2: Herring
  Email1: herring@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: FleCSI Task Generalization
  Field: parallel library programming
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: Task-based parallelism imposes constraints on units of computational work
    to allow them to be dynamically scheduled for optimum hardware utilization. More
    sophsticated models for launching tasks can relax certain of these constraints
    and afford applications more expressive power in writing their tasks. Furthermore,
    additional information provided by the application can be used to optimize the
    execution of tasks with unusual semantics (e.g., that need filesystem access).
    We plan to explore the space of task semantics, identify which generalizations
    can be efficiently supported in FleCSI, and extend it to provide those which are
    most valuable for practical applications.
  Desired: C++ programming parallel programming (in any or all of MPI, CUDA, Kokkos,
    OpenMP, or kernel threads) high-performance computing environments computational
    methods
  Comments1: FleCSI utilizes, directly or indirectly, various sophisticated programming
    techniques, in parallel or otherwise. We expect that training in these techniques
    would be part of the collaboration.
  Special: International OK
- "\uFEFFSubmission": strack139s1
  Status: Accept
  Name1: Jan
  Name2: Ciesko
  Email1: jciesko@sandia.gov
  Institution: Sandia National Laboratories
  Title: Next Gen Communication APIs in HPC
  Field: GPU Parallel Programming
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: Communication offloading to GPUs represents a hot topic in science and
    industry. While many algorithms could benefit from this capability in terms of
    performance and programmability, novel communication APIs are required that are
    more suitable for GPU execution. In this work we examine the current PGAS support
    for distributed parallel programming in Kokkos and evaluate that implementation
    in comparison to proposals coming from the MPI Forum as well as hardware manufactures
    such as NVIDIA. Using micro-benchmarks we showcase performance and programmability
    differences and conclude this work with recommendations on future communication
    APIs for scientific computing and HPC.
  Desired: Parallel Programming, GPU Programming, C++
  Special: In-Person Only; U.S. Citizen Only; Permanent Resident OK; International
    OK
- "\uFEFFSubmission": strack140s1
  Status: Accept
  Name1: Ishan
  Name2: Srivastava
  Email1: isriva@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Multiscale Modeling of Complex Fluids and Multiphase Flows
  Field: Computational Fluid Dynamics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing;
    Machine Learning and AI
  Abstract: We are developing numerical algorithms and computational models to simulate
    the dynamics of particulate materials, complex fluids and multiphase flows. The
    proposed approach involves integrating a particle-scale representation such as
    the discrete element method (DEM), a coarse-grained representation such as particle-in-cell
    (PIC), and a continuum-scale PDE representation of these materials using the tools
    of adaptive mesh and algorithm refinement, and data-driven machine learning methods.
    The overarching goal will be a multiscale modeling framework that can simulate
    a wide variety of particulate materials and complex fluids, and is performant
    on manycore/GPU-based high performance computing (HPC) platforms. Another goal
    of this project is to conduct large-scale simulations of complex fluids and multiphase
    flows on HPC platforms in application spaces such as bioreactors and advanced
    manufacturing.
  Desired: Basic knowledge of C++ programming and Python scripting. Background in
    Applied Mathematics, Physics, or Physical Sciences/Engineering. Basic understanding
    of applied mathematics, computational methods, scientific computing, and fluid
    dynamics.
  Special: In-Person Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack141s1
  Status: Accept
  Name1: Hong
  Name2: Zhang
  Email1: hzhang@mcs.anl.gov
  Institution: Argonne National Laboratory
  Title: Scientific Computing using the PETSc/TAO Library on Exascale Machines
  Field: HPC
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: Robust, efficient, and scalable numerical solvers for simulations based
    on partial differential equations (PDEs) and networks are at the heart of computational
    science. PETSc, the Portable, Extensible Toolkit for Scientific Computation (https://petsc.org),
    is a suite of data structures and routines for the scalable (parallel) solution
    of scientific applications modeled by PDEs, including related functionality for
    numerical optimization in TAO (Toolkit for Advanced Optimization). This project
    will focus on advances in PETSc/TAO composable solvers, which provide the core
    of scalable multiphysics and multiscale applications, including fusion, geosciences,
    power grids, nuclear energy, and more. Areas of potential work include developing
    efficient and scalable algorithms for linear, nonlinear, and timestepping solvers;
    creating example programs to demonstrate functionality and explore performance
    on extreme-scale architectures; and advancing new capabilities as motivated by
    the needs of data-driven computing and machine learning. Students are expected
    to gain hands-on numerical programming experience on state- of-the-art parallel
    computers. Students will apply the algorithms and techniques learned to a project
    in either their own field (particularly encouraged) or suggested by the mentor.
  Desired: Mathematical understanding, computer coding skills, motivation and hard
    working
  Special: International OK
- "\uFEFFSubmission": strack142s1
  Status: Accept
  Name1: Helen
  Name2: He
  Email1: yhe@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: OpenMP Common Core with Python
  Field: High Performance Computing Programming Model
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: "OpenMP is the de facto standard for writing parallel applications for
    shared memory computers. Born ~25 years ago in 1997, it runs on just about every
    shared memory platform on the market. Itâ€™s also very complicated with the Language
    Specification of over 600 pages. Most OpenMP programmers however only use around
    21 items from the Language Specification. We call these 21 items the â€œOpenMP
    Common Coreâ€\x9D. By focusing on the common core, we make OpenMP what it was
    always meant to be: a simple API for parallel application programmers. Most C/C++/Fortran
    compilers have OpenMP support. The OpenMP Common Core Book published in 2019 by
    Tim Mattson, Helen He, and Alice Koniges provided example codes mostly in C (plus
    the Fortran supplement), to illustrate OpenMP Common Core concepts. PyOMP is a
    new project based on Numba to allow Python programmers to use OpenMP directives
    in their Python code. The proposed SRP project is to learn OpenMP Common Core
    first, then install PyOMP on the NERSC system or your own laptop and implement
    selected OpenMP Common Core example codes in Python."
  Desired: Python, HPC parallel programming concept, C/C++ or Fortran
  Special: Minimum GPA (specify what GPA in comments below); Permanent Resident OK
  Comments2: minimum GPA 3.33
- "\uFEFFSubmission": strack143s1
  Status: Accept
  Name1: Nan
  Name2: Ding
  Email1: nanding@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Explore the performance of GPU-initiated communications and CPU-initiated
    communication on heterogeneous architectures
  Field: HPC Communications
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: Effective programming models offer programmers the ability to harness
    the capabilities of the underlying platform. For decades, the CPU-initiated Message
    Passing Interface (MPI) has become a de facto standard for communication among
    processes running on distributed memory systems. As high-performance GPU computing
    becomes the trend, GPU-initiated communication becomes a viable solution for multi-GPU
    scaling. However, the lack of deep understanding of GPU-initiated communication
    performance and its impact on an application's performance becomes a hurdle. As
    such, the proposed topic is to explore the performance of GPU-initiated communications
    and CPU-initiated communication by using or creating representative benchmarks
    on Perlmutter, Frontier, and possibly Aurora. The work may includes writing benchmark
    using CPU- and GPU-initiated communication.
  Desired: knows MPI programming Passion about research work
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only; U.S.
    Citizen Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack144s1
  Status: Accept
  Name1: Russell
  Name2: Whitesides
  Email1: whitesides1@llnl.gov
  Institution: Lawrence Livermore National Laboratory
  Title: Future Clean Jet Fuels
  Field: Combustion
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing
  Abstract: This project will explore impacts of sustainable aviation fuels on performance
    of combustion in jet engines. We will investigate fuel property effects on combustion
    metrics such as stability, efficiency, emissions. To capture the chemical kinetic
    effects of the fuel we will use detailed models and highly resolved grids, necessitating
    the use of high-performance computing platforms. The study can be focused on combustion
    physics, computational performance of the simulation software, or some mix of
    the two.
  Desired: 'Skills: engineering or computer science Interests: Energy, climate, combustion'
  Special: International OK
- "\uFEFFSubmission": strack145s1
  Status: Accept
  Name1: Terry
  Name2: Jones
  Email1: trj@ornl.gov
  Institution: Oak Ridge National Laboratory
  Title: Memory Tools for High Performance Computing
  Field: Computer Science
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: The recent emergence of new memory technologies and multi-tier memory
    architectures has disrupted the traditional view of memory as a single block of
    volatile storage with uniform performance. Several options for managing data on
    heterogeneous memory platforms now exist, but current approaches either rely on
    inflexible, and often inefficient, hardware-based caching, or they require expert
    knowledge and source code modification to utilize the different performance and
    capabilities within each memory tier. We are researching a new software-based
    framework to collect and apply memory management guidance for applications on
    heterogeneous memory platforms. The framework, together with new tools, combines
    a generic runtime API with automated program profiling and analysis to achieve
    data management that is both efficient and portable across multiple memory architectures.
  Desired: â€¢ basic computer science skills â€¢ C programming language â€¢ willingness
    to learn
  Special: Permanent Resident OK
- "\uFEFFSubmission": strack146s1
  Status: Accept
  Name1: Benjamin
  Name2: Priest
  Email1: priest2@llnl.gov
  Institution: Lawrence Livermore National Laboratory
  Title: HPC-scale data science for applications
  Field: high performance computing, scientific computing, statistics, machine learning
  Topics: Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing; Machine Learning and AI
  Abstract: Modern Department of Energy science missions from cosmology to biosecurity
    to climate to computer security to fusion are collecting increasingly enormous
    datasets whose exploitation requires novel approaches and algorithms. For example,
    the Vera C. Rubin Observatory (https://www.lsst.org/) will produce 20 trillion
    bytes of cosmology image data per night for 10 years, which is well beyond the
    throughput capabilities of conventional astronomy codes. Furthermore, nucleotide,
    protein, and antibody sequence catalogues continue to grow in both observation
    size and count, and so require novel solutions for even basic machine learning
    tasks such as clustering. Our group works on solutions to these and other problems
    that are scalable, fast, and both theoretically and statistically motivated. This
    summer project will involve implementing data science codes for deployment on
    Lawrence Livermore's statoe-of-the-art computers in service to improving the nation's
    ability to handle one of these critical problems. We expect the project to involve
    collaborating with several subject matter experts depending on the specifics of
    the task, which could include physicists, applied mathematicians, computer scientists,
    and statisticians.
  Desired: Python and/or C++, high performance computing, statistics and/or graph
    algorithms, applied mathematics, interest in applications such as space, climate,
    or network analysis.
  Special: other
  Other: Remote Only
- "\uFEFFSubmission": strack147s1
  Status: Accept
  Name1: Michael
  Name2: Jantz
  Email1: mrjantz@utk.edu
  Institution: Oak Ridge National Laboratory
  Title: Simplified Interface to Complex Memory
  Field: Software Systems
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: In recent years, multiple concurrent trends, including the proliferation
    of AI and other data-driven analyses, rising CPU core counts, and the relative
    stagnation of DRAM performance and capacity scaling, have combined to place enormous
    strain on modern memory systems. At the same time, several new technologies (e.g.,
    high-bandwidth and non-volatile memories), as well as new memory interconnect
    options (e.g., Compute Express Link), are bringing new capabilities that can potentially
    address the limitations of conventional memory hardware. As a result, many computing
    systems are adopting a diverse mix of memory devices and organizations, with the
    hope that the unique benefits and capabilities of different technologies can be
    seamlessly combined into a single architecture. The Simplified Interface to Complex
    Memory (SICM) project aims to create new tools and infrastructure for applications
    that execute on architectures with complex memory resources. SICM currently includes
    a low-level interface that allows applications to view and manage heterogeneous
    resources directly as well as a high-level interface with tools and facilities
    to manage memory resources automatically, without requiring changes to application
    software.
  Desired: We are searching for students that enjoy programming and are particular
    interested in systems topics, such as operating systems, compilers, and/or memory
    allocators. Experience with or interest in tools and analyses for monitoring and
    understanding program behavior is also desired.
  Special: In-Person Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack148s1
  Status: Accept
  Name1: Tadashi
  Name2: Ogitsu
  Email1: ogitsu1@llnl.gov
  Institution: Lawrence Livermore National Laboratory
  Title: Quantum dynamics simulation
  Field: Materials Science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.)
  Abstract: Our BES funded software center NPNEQ intends to develop the methods and
    software to simulate time evolution of coupled electron-ion dynamics beyond perturbative
    approach, which is crucial for describing quantum nature of nonequilibrium dynamics.
  Desired: High level programing languages such as C++, Fortran, python as well as
    being familiar with parallelization methods such as MPI.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack149s1
  Status: Accept
  Name1: Pablo
  Name2: Seleson
  Email1: selesonpd@ornl.gov
  Institution: Oak Ridge National Laboratory
  Title: Peridynamics Modeling and Simulation for Exascale Fracture Computations
  Field: Applied and Computational Mathematics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: 'Computational fracture modeling is an ongoing challenge in computational
    science and engineering. Peridynamics is a nonlocal reformulation of classical
    continuum mechanics designed to simulate fractures thus making it an attractive
    framework for modeling material failure and damage across many application domains.
    This has been reflected in an exponential growth in the number of peridynamics
    researchers and publications worldwide over the last two decades. We have developed
    at Oak Ridge National Laboratory (ORNL) an exascale-capable, GPU-enabled, and
    performance-portable peridynamics code, CabanaPD (https://github.com/ORNL/CabanaPD).
    CabanaPD has been tested on the Oak Ridge Leadership Computing Facility (OLCF)
    leadership-class computing resources, Summit and Frontier supercomputers, and
    is built on two main libraries: Kokkos and Cabana, both developed through the
    Exascale Computing Project (ECP). This project will develop mathematical and computational
    methods to advance the state of the art of peridynamics modeling and simulation,
    with the end goal of enhancing current features of the peridynamics CabanaPD code.'
  Desired: "#NAME?"
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack150s1
  Status: Pre-Match+Workshop
  Name1: Tanwi
  Name2: Mallick
  Email1: tmallick@anl.gov
  Institution: Argonne National Laboratory
  Title: Spatiotemporal modeling using machine learning techniques
  Field: Spatiotemporal modeling, Graph neural network, Clustering
  Topics: Machine Learning and AI
  Abstract: Many real-world phenomena, such as traffic flow on road networks, data
    transfer on the HPC Interconnect Network, load balancing in power grids, and regional
    rainfall, are spatiotemporal in nature. These complex systems are dynamic, evolving
    over both time and space. For the aforementioned scientific studies, it is critical
    to accurately predict the future behaviors of these spatiotemporal systems, cluster
    the data into meaningful groups to unveil different patterns and anomalies and
    accelerate spatiotemporal models by optimizing their performance and reducing
    computation time. In this project, we aim to develop and fine-tune a machine learning
    model for enhanced spatiotemporal modeling, targeting real-world phenomena like
    traffic flow, HPC Interconnect Network traffic, and regional rainfall.
  Desired: Python programming, TensorFlow, or PyTorch programming
  Special: other
  Other: None
- "\uFEFFSubmission": strack151s1
  Status: Accept
  Name1: Jeffrey
  Name2: Larson
  Email1: jmlarson@anl.gov
  Institution: Argonne National Laboratory
  Title: Numerical optimization of simulations
  Field: Computational Science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: We are seeking SRP collaborators looking to solve complex numerical optimization
    problems. Researchers with interests in specific application problems or interests
    in numerical optimization algorithms are both encouraged.
  Desired: Researchers at any point in their career looking to apply/develop state-of-the-art
    numerical optimization techniques to application problems from any scientific
    domain are desired.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack152s1
  Status: Accept
  Name1: Mah Kadidia
  Name2: Konate
  Email1: kadidiakonate@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Machine Learning for Jobs queue Wait time prediction
  Field: Machine learning
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing; Machine Learning and AI
  Abstract: The era of supercomputing and data science presents novel challenges and
    opportunities. Supercomputers such as Cori and Perlmutter, with their incredible
    processing power, are often tasked with running numerous complex jobs concurrently.
    Efficient management of these jobs, especially determining their queue wait times,
    is critical to optimizing the system's overall performance. This project, titled
    "Queue Wait Time Prediction of Perlmutter, aimed to address this very issue.
  Desired: Experience with writing Python code, Experience with machine learning and
    data visulization
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack153s1
  Status: Pre-Match+Workshop
  Name1: Dan
  Name2: Martin
  Email1: dfmartin@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Tokamak modeling
  Field: Numerical modeling
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.)
  Abstract: When finally harnessed, nuclear fusion holds the promise of almost limitless
    energy. We are partners in a project to better understand turbulence in tokamaks,
    a form of fusion reactor by improving existing models. Project ideas include improving
    numerics and performance of the model, adding additional physics to the model,
    and simulation-based projects to understand specific scenarios.
  Desired: 'Specific background depends on the specific project focus, but generally:
    applied mathematics, software development (C++, python), physics, climate science,
    etc.'
  Comments1: This is a placeholder for a range of project ideas under a range of applications.
    We can come up with specific projects based on your skills and interests.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack154s1
  Status: Accept
  Name1: Otto
  Name2: Venezuela
  Email1: venezuela1@llnl.gov
  Institution: Lawrence Livermore National Laboratory
  Title: HPC Cloud DevOps
  Field: HPC ML / AI DevOps
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); High-Performance Computing;
    Machine Learning and AI
  Abstract: LLNL and Livermore Computing (LC) invite you to apply to our DevOps internship
    program next summer. Come and join us as we start building new workflow pipelines,
    infrastructure for ML models, and intelligent apps. We will explore MLOps which
    will help Data Scientist in LLNL to automate model training, store, and deploy
    them at scale. We will be using on-prem Kubernetes/OpenShift cluster with GPU
    enabled server to build the next DevOps infrastructure for our scientist community.
  Desired: eager to learn new things! unix / linux
  Special: U.S. Citizen Only
- "\uFEFFSubmission": strack155s1
  Status: Pre-Match+Workshop
  Name1: Pedro
  Name2: Valero-Lara
  Email1: valerolarap@ornl.gov
  Institution: Oak Ridge National Laboratory
  Title: Challenges/Opportunities for the Extreme Heterogeneity and HPC-AI era
  Field: High Performance Computing
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: 'This project is aimed at the implementation, evaluation and optimization
    of novel performance portable and heterogeneous programming solutions for the
    upcoming extreme heterogeneity era in computing. The project includes the design
    of novel software solutions on the available software and hardware platforms.
    Learning objectives for the applicant include: i) develop HPC codes based on performance
    portable programming models, such as OpenMP/OpenACC, C++, Kokkos, Julia, task-based
    runtimes, on current HPC and heterogeneous (CPU+GPU) architectures, ii) acquire
    skills in both, software solutions and HPC codes implementation, iii) gain experience
    in performance analysis on HPC architectures.'
  Desired: Computer Science Programming Languages Linux
  Special: In-Person Only; Permanent Resident OK
- "\uFEFFSubmission": strack156s1
  Status: Accept
  Name1: M. Scot
  Name2: Swan
  Email1: mswan@sandia.gov
  Institution: Sandia National Laboratories
  Title: Data Analysis to Speed Up Supercomputers
  Field: Data Analysis, Computer Science, High Performance Computing
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing
  Abstract: Our work would fall under the HPC/Application Metrology umbrella ("metrology"
    is the study of measuring stuff). So we want to measure the performance of the
    supercomputer, the performance of the applications that run on them, and how the
    two interact. I am interested in finding someone to help me speed up our High
    Performance Computing (HPC) supercomputers. We know that there are bottlenecks
    in our simulations, like memory, CPU, network, or filesystem limitations. Often
    these bottlenecks are temporary, so they are hard to find or reproduce. We need
    someone to run applications on the supercomputers and then analyze the performance
    data to find performance anomalies and then try to find a cause for them. When
    we have data showing problems, we can pass that to the system administrators for
    them to address, speeding up the supercomputer so more simulations can be done
    faster.
  Desired: Interest in learning how to use Linux and the Command Line. Interest in
    learning how to write Python code to analyze data. Interest in running small-to-large
    simulations on supercomputers. Interest in working with system administrators
    and computational physicists.
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only; U.S.
    Citizen Only
  Comments2: 'minimum GPA: 3.0/4.0'
- "\uFEFFSubmission": strack158s1
  Status: Accept
  Name1: Nitin
  Name2: Daphalapurkar
  Email1: nitin@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Mechanics of granular materials--coupled continuum-mesoscale modeling
  Field: Solid Mechanics; Materials science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Machine Learning and AI
  Abstract: Mesoscale simulations implementing inelastic deformation of granular matter
    for accurate predictions of a moving shock. Unlike solids and fluids, the dynamic
    response of granular materials has the additional complexity of being dominated
    by the presence of irregular spaces between the grains. Under dynamic deformation,
    a grain squashes from impact, crushes, and squeezes through available pore spaces.
    The statistical nature of the complex shock response arising from tens of thousands
    of grains may result in a different compaction state than what was intended during
    its performance. The solution to this problem is at the intersection of geoscience
    and computational solid mechanics, which strives to develop a physically based,
    mesoscale-consistent continuum description for granular materials.
  Desired: Numerical simulations using solid mechanics methods, e.g. Finite element
    methods; discrete element methods, material point method. Multiscale coupling
    of physics, e.g. definition of stress tensor, temperature and other such variables;
    Machine Learning approach for predicting granular materials under pressure and
    shear loading.
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only; U.S.
    Citizen Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack160s1
  Status: Pre-Match+Workshop
  Name1: Mitchell
  Name2: Wood
  Email1: mitwood@sandia.gov
  Institution: Sandia National Laboratories
  Title: Data-driven Models for Material Science and Beyond
  Field: Multiscale Materials Modeling
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing;
    Machine Learning and AI; National Security
  Abstract: Experiments to study materials extreme environments (temperature, pressure,
    strain rate) are challenging and time consumptive, therefore we turn to modeling
    tools to refine and predict outcomes beforehand. Ideal computational models balance
    absolute physical accuracy against approximate but computationally lightweight
    constitutive inputs. In addition, with exascale super computers arriving in the
    near future, it is timely to ask whether our simulation software is capable of
    matching this unprecedented computing capability. While many research challenges
    in material physics, chemistry and biology lie just out of reach on peta-scale
    machines due to length and time restrictions inherent to Molecular Dynamics and
    electronic structure methods, questions of the accuracy of our predictions will
    continue to linger. This is particularly true for complex alloys, composites of
    disparate components as well as materials in extremes of temperature, pressure
    and radiation exposure. Here we aim to break the normal accuracy-cost tradeoffs
    by using machine learned models that scale to the largest supercomputing platforms
    in the world.
  Desired: Material Science, Physics, Chemistry, Python, High Performance Computing
  Special: In-Person Only; U.S. Citizen Only
- "\uFEFFSubmission": strack161s1
  Status: Accept
  Name1: Warren
  Name2: Davis
  Email1: wldavis@sandia.gov
  Institution: Sandia National Laboratories
  Title: In-Situ Machine Learning
  Field: Computer Science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); High-Performance
    Computing; Machine Learning and AI
  Abstract: "DOE research often involves discovering new, â€œinterestingâ€\x9D events
    in high-fidelity physics-based HPC simulations. Standard anomaly detection algorithms
    are limited, requiring the capture of all the data for post processing, or requiring
    high-bandwidth in-situ communication. Our research focuses on creating more efficient
    ways to detect anomalies in-situ, thus facilitating more precisely targeted event
    capture."
  Desired: Python programming Mathematics
  Special: Minimum GPA (specify what GPA in comments below)
  Comments2: '3'
- "\uFEFFSubmission": strack162s1
  Status: Accept
  Name1: Suaznne
  Name2: Parete-Koon
  Email1: paretekoonst@ornl.gov
  Institution: Oak Ridge National Laboratory
  Title: HPC/AI/Data Sci. Project-Based Curriculum Building
  Field: HPC, AI, Data Science
  Topics: Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing; Machine Learning and AI
  Abstract: One of the best ways to learn a new skill it to teach it. This project
    will focus on preparing introductory High-Performance Computing (HPC) material
    to enable individuals to gain foundational HPC skills for advanced computing and
    bridge the gap between advanced HPC programs and currently available courses in
    Computer Science undergraduate curriculum. The goal is to provide clear and easily
    accessible tutorials that will educate newcomers on the technical aspects of HPC.
    These tutorials will include definitions of commonly used HPC terms, concepts,
    applications, and hands-on programming exercises. This project will contribute
    to a future diverse HPC workforce by making HPC and Data Science more accessible,
    not just technically but addressing cultural and economic barriers to reach out
    to underrepresented populations. Students will first apply the core computing
    skills to smaller-scale datasets and codes and develop more advanced skills, such
    as parallelizing their code and handlining larger datasets. They will then appreciate
    the value of parallel computing and how one can harness the analytics capabilities
    of HPC to solve complex computational problems with high societal impact. We believe
    this project aligns with the goals of the SRP program in building the future workforce
    for HPC, AI, and Data science.
  Desired: Passion to learn
  Comments1: This team of mentors includes Suzanne Parete-Koon, John Holman (holmenjk@ornl.gov),
    Togo Odbadrakh (odbadrakhtt@ornl.gov , and William Godoy (godoywf@ornl.gov)- We
    are open to mentoring 1 ECP Intro the HPC Bootcamp student and 1 Student and Faculty
    team. Please no more than that! We are all running a Hackathon at OLCF during
    the matching workshop and will need to rotate through the workshop. Please invite
    all of us. Is there a place that I can submit everyone else's bios and pictures?
    I think having my teammates bios will help students choose us. We are a village
    of HPC skills and mentorship.
  Special: other
  Other: Since I don't know our funding source, I can guarantee that we can host International-
    but not opposed in principle.
- "\uFEFFSubmission": strack163s1
  Status: Accept
  Name1: Megan
  Name2: McCarthy
  Email1: megmcca@sandia.gov
  Institution: Sandia National Laboratories
  Title: Accelerating machine-learned interatomic potential development for nanoscale
    materials science
  Field: Computational materials science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.)
  Abstract: Our group uses a combination of atomistic multiscale simulation methods,
    paired with machine learning techniques, to create powerful near-quantum-accurate
    models for atomic interactions. These models are called machine-learned interatomic
    potentials and are used in molecular dynamics (MD) simulations, which simulate
    a material atom-by-atom. MD is widely used to both understand nanoscale behavior
    in well-known engineering materials such as iron and silicon and also to discover
    and characterize new materials such as high entropy alloys. In our group, we look
    specifically at materials used extreme environments, such as those found inside
    nuclear fusion and fission reactors, and simulate them at very large scales on
    high-performance computing systems (HPC, also sometimes called supercomputers).
    Creating new interatomic potentials for MD is very challenging and is thus currently
    a huge bottleneck in the world of nanoscale materials modeling. The intern's project
    would involve working with an interdisciplinary team of scientists and other interns
    on tackling the science of interatomic potential development itself, with an aim
    to speed up production of these machine-learned potentials and thus accelerate
    materials science discovery. The specific project would be adjusted to the student's
    background and interests.
  Desired: Materials science and engineering (all specialties welcome), coding / programming,
    data science
  Comments1: Some coding background (1 or 2 standard undergrad classes) is ideal but
    is not strictly required. No background in machine learning techniques is required.
  Special: U.S. Citizen Only; Permanent Resident OK
- "\uFEFFSubmission": strack164s1
  Status: Accept
  Name1: Mark
  Name2: Miller
  Email1: miller86@llnl.gov
  Institution: Lawrence Livermore National Laboratory
  Title: Visualization and Data Analysis
  Field: Visualization and Data Analysis
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing
  Abstract: We have various projects related to scientific visualization and data
    analysis. We also have projects aimed at investigating and tuning performance
    of visualization and analysis workflows. We can work together to help refine specific
    goals for a summer internship.
  Desired: An interest in working on high performance computing projects involving
    visualizing and analyzing data. Some experience with writing and debugging software
    (Java,C,C++,Fortran,Python,Basic,etc.) would be useful.
  Comments1: In-person, remote and hybrid possible. In-person preferred but non-essential.
  Special: other
  Other: None
  Comments2: International likely ok only via subcontract to SHI
- "\uFEFFSubmission": strack169s1
  Status: Accept
  Name1: Patricia
  Name2: Grubel
  Email1: pagrubel@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Software development
  Field: High Performance Computing
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: We are looking for students interested in applying their computer science
    skills while learning about real world applications. The work will be on helping
    develop portions of a workflow orchestration system that interfaces with the user,
    application and the underlying HPC systems.
  Desired: Python, some database experience, Object Oriented Programming would be
    desirable. Linux bash scripting. Interest in containerization of applications
    (be willing to learn), cloud computing (optional) or work on front end gui may
    also be desirable.
  Special: Minimum GPA (specify what GPA in comments below); In-Person Only; U.S.
    Citizen Only; Permanent Resident OK
  Comments2: 3.0, some restrictions on international students
- "\uFEFFSubmission": strack170s1
  Status: Accept
  Name1: Philipp
  Name2: Edelmann
  Email1: pedelmann@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: A modern approach to implicit fluid dynamics
  Field: Computational Fluid Dynamics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing
  Abstract: Computational fluid dynamics (CFD) is used every day in many fields of
    science from biology to astrophysics. Yet simulating slow flows (compared to the
    speed of sound) is a hard problem both in terms of numerical accuracy and in terms
    of efficiency, in particular when explicit time stepping is used. Recent work
    from stellar astrophysics has shown that it is feasible to run three-dimensional
    (3D) CFD simulations with fully implicit time stepping. This is significantly
    more complex and involves the use of linear and nonlinear iterative solvers. The
    trends of the past years and especially the new supercomputers of the exascale
    era have shown that support for GPUs is essential. At the same time traditional
    methods of parallelization using the Message Passing Interface (MPI) have trouble
    coping with heterogeneous (from different physics modules) workloads on large
    systems, which is why task-based approaches to parallelization have gained popularity.
    LANL developed a modern C++ framework FleCSI to help writing multiphysics codes
    while providing abstractions for details of the task runtime and GPU vendor library.
    We propose to implement a prototype 3D CFD code using FleCSI and our own solvers
    library FleCSolve and test it on LANL's new supercomputer Vendado.
  Desired: 'The most important thing for this project is an interest and enjoyment
    of programming and numerical simulations. This is an exploratory project that
    can be focused on different aspects of computer science, applied math, or physics
    depending on the interests of the student. A general background in programming
    is required, but other skills can be picked up during the project as needed. Other
    useful (but not required) skills are: modern C++, (non)linear iterative solvers,
    computational fluid dynamics methods, high-performance computing'
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack171s1
  Status: Accept
  Name1: Ember
  Name2: Sikorski
  Email1: elsikor@sandia.gov
  Institution: Sandia National Laboratories
  Title: Material Models for Fusion Energy
  Field: Atomistic Materials Modeling
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.)
  Abstract: Achieving nuclear fusion power on earth requires incredibly durable materials
    capable of housing a tiny sun. We can use quantum materials modeling to make predictions
    about the behavior of prospective fusion materials, without the need for experiments.
    However, quantum models are very computationally expensive. Machine learning allows
    us to bypass much of the expense and enable larger scale modeling with quantum
    accuracy. With these models we can study thermomechanical properties and/or plasma
    interactions in fusion materials. Now, we can design fusion materials at the nanoscale
    for better performance. Project ideas include classical modeling of the fusion
    material, quantum modeling for the machine learning training set, or optimizing
    the code to better find the machine learning hyper-parameters.
  Desired: Looking for students interested in applied research for nuclear energy,
    aerospace, or other applications with extreme environments.
  Comments1: If interested, please contact Meg McCarthy (SNL) as I will be unavailable
    during the matching workshop.
  Special: In-Person Only; U.S. Citizen Only
- "\uFEFFSubmission": strack172s1
  Status: Accept
  Name1: Roel
  Name2: Van Beeumen
  Email1: rvanbeeumen@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Randomized solvers for tensor eigenvalue problems
  Field: Numerical Linear Algebra
  Topics: High-Performance Computing Quantum Computing and Information Science
  Abstract: Eigenvalue computations are at the core of simulations in many applications,
    including quantum physics, material science, and electronic structure computations.
    On the other hand, randomized algorithms are currently gaining more attention
    because of their potential for both reducing computational complexity and data
    movement on the emerging heterogeneous computing systems. Project ideas could
    include comparing and testing different randomization schemes, incorporating mixed-precision,
    improving (CPU/GPU) performance, etc. Current and near-term quantum computers,
    also known as noisy intermediate-scale quantum (NISQ) computers, are characterized
    by low qubit counts, short qubit decoherence times, and high gate error rates.
    On the other hand, rapid progress in both quantum hardware and software results
    in continuous simulation needs of novel/modified quantum algorithms. The QCLAB++
    simulation software package, developed at LBNL, is an object-oriented and fully
    templated C++ package for creating and representing quantum circuits. QCLAB++
    can be used for rapid prototyping and testing of quantum algorithms, and allows
    for fast algorithm development and discovery. Project ideas could include improving
    (CPU/GPU) performance, adding different noise models, and expanding the quantum
    algorithmsâ€™ base.
  Desired: 'Specific background depends on the specific project focus, but generally:
    applied mathematics, numerical algorithm design, software development (C++, Matlab),
    etc.'
  Special: In-Person Only
- "\uFEFFSubmission": strack175s1
  Status: Accept
  Name1: Mark
  Name2: Paris
  Email1: mparis@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Advanced computational methods for applied nuclear reaction theory
  Field: Theoretical and computational nuclear physics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); High-Performance
    Computing; Machine Learning and AI
  Abstract: The Theoretical Division at Los Alamos National Laboratory brings a diverse
    array of expertise to understanding nuclear fusion and fission reactions -- the
    fundamental, underlying component of systems driven by nuclear fuels. Exciting,
    recent developments in confined fusion systems at facilities around the world
    demonstrate that terrestrial nuclear fusion is attainable, reinforcing the importance
    of understanding the basic nuclear reactions governing these systems. In addition
    to their relevance in the production of terrestrial energy reactors, nuclear reactions
    are foundational elements in understanding energy production and structure of
    stars, the ``Big Bang'' of the early universe, and the extreme phenomena of explosive
    supernovae and their production of neutron stars and black holes. Our mentoring
    team (Hlophe, Lovell &amp; Paris) leverages the diverse personal backgrounds and
    expertise of its members to provide effective mentorship for students from a wide
    variety of socioeconomic environments and levels of academic preparation. Theoretical
    Division scientists seek to broaden and deepen our research portfolio in theoretical
    and computational nuclear physics. We employ standard, few- and many-body techniques
    in combination with optimization methods, to more efficiently investigate reactions
    of importance for these sorts of applications in fundamental science, nuclear
    safety and security, and nuclear energy.
  Desired: Interest in, excitement about, and experience in solving physics problems
    with computers are all welcome.
  Comments1: We are planning to have a co-mentorship model with three T-2 staff members
    (Amy Lovell, Linda Hlophe, and Mark Paris). Amy is an early career scientist,
    with T-2 since 2018. Linda Hlophe is taking his first visiting assistant professorship
    (with MSU) in T-2 since August of this year. Mark Paris has been in T-2 since
    2012.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack176s1
  Status: Accept
  Name1: Erika
  Name2: Ye
  Email1: erikaye@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Quantum-inspired methods for solving PDEs
  Field: High-dimensional PDEs
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Quantum Computing and Information
    Science
  Abstract: Partial differential equations are used across many scientific fields
    to describe physical phenomena. However, nonlinear PDEs can be difficult to understand
    analytically and also difficult to simulate numerically. In particular, numerical
    simulation methods suffer from the curse of dimensionality, meaning that the number
    of degrees of freedom increase exponentially with problem dimension. Quantum-inspired
    algorithms offer a way to systemically reduce the degrees of freedom, potentially
    allowing for (sub)exponential reduction in computational cost. These algorithms
    are gaining in popularity and have been used to solve Navier-Stokes and the Vlasov
    equation with surprising success. This project can take many directions, such
    as extending these methods to different PDEs or considering problems with complex
    geometries.
  Desired: Coding experience Linear algebra Basic quantum mechanics Numerical simulation
    background
  Comments1: I may have to missed parts of the matching workshop
  Special: Minimum GPA (specify what GPA in comments below); Permanent Resident OK;
    International OK
  Comments2: 3.0/4.0
- "\uFEFFSubmission": strack177s1
  Status: Accept
  Name1: Bert
  Name2: Debusschere
  Email1: bjdebus@sandia.gov
  Institution: Sandia National Laboratories
  Title: Uncertainty Quantification in Computational Simulations
  Field: Computational Science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing; Machine Learning and AI
  Abstract: Uncertainty Quantification (UQ) is the assessment of the confidence in
    we can have in computational results based on the uncertainty in the model and
    its input parameters. It also involves the calibration of models based on information
    in available data sets. Our workgroup focuses on the development and implementation
    of UQ methods in open-source software, as well as the application of these methods
    to relevant problems in computational sciences. We are looking for 1 â€“ 2 interns
    to help with the software engineering of our Python open-source UQ tools, as well
    as the application of these tools to studies in nuclear fusion energy.
  Desired: 'The skills we look for will depend on the project focus, but generally
    we are interested in any of the following: an inquisitive mind, software development
    (Python), applied mathematics, statistics, Bayesian methods, github, etc.'
  Comments1: The topic area described here acts as an umbrella for many possible internship
    projects. We will be happy to come up with specific projects that fit your skills
    and interests.
  Special: International OK
- "\uFEFFSubmission": strack178s1
  Status: Accept
  Name1: David
  Name2: Williams-Young
  Email1: dbwy@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Enabling the Next Generation Quantum Simulations with Modern High-Performance
    Computing
  Field: Computational Physics and Numerical Linear Algebra
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: In this research, we will develop novel methods for the efficient solution
    of the quantum many-body problem by leveraging the latest advances in modern high-performance
    computing and sparse numerical linear algebra. Key applications of this work will
    be accelerating scientific simulations in computational chemistry, nuclear physics,
    high-energy physics and quantum information science, each of which hold significant
    potential to advance our understanding of the universe and the fundamental physical
    laws that govern it. Researchers will gain hands-on experience in these and related
    fields and work in a highly-collaborative environment, on-site at Lawrence Berkeley
    National Lab.
  Desired: Programming experience and a background in quantum mechanics, computational
    physics and/or linear algebra are highly desirable, but not required. Experience
    programing GPUs and working with distributed computing (MPI) would increase the
    scope of potential projects.
  Special: In-Person Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack179s1
  Status: Under Evaluation
  Name1: Li
  Name2: Tang
  Email1: ltang@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: High-Performance Computing with Python
  Field: High-Performance Computing
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing
  Abstract: LANL's Venado, the first NVIDIA Grace-Hopper supercomputer in the US,
    will be ready in early 2024. NVIDIA's Grace-Hopper integrates its latest Grace
    CPU and H100 GPU on the same chip for faster CPU-GPU data movement, and Venado
    provides an exotic liquid cooling system for maximized system performance and
    reliability. To run large-scale simulations using GPUs on Venado, conventional
    HPC programming solutions include the mix of CUDA (GPU programming) and MPI (node
    communication), and the Kokkos ecosystem. However, these solutions usually require
    significant programming (e.g., C++ and MPI) and hardware expertise (e.g., GPU
    architecture). To strengthen LANL's HPC productivity on the rapidly evolving heterogeneous
    supercomputers with GPUs, we will evaluate an innovative HPC programming paradigm,
    programming physics simulations using NumPy, by accelerating LANL's physics simulations
    on hundreds of Venado GPU nodes.
  Desired: Python, NumPy
  Special: In-Person Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack180s1
  Status: Accept
  Name1: Ken
  Name2: Raffenetti
  Email1: raffenet@anl.gov
  Institution: Argonne National Laboratory
  Title: 'MPICH: A High Performance and Widely Portable Implementation of the Message
    Passing Interface (MPI) Standard'
  Field: Parallel Programming Models and Runtime
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing; Machine
    Learning and AI
  Abstract: MPICH is a widely used, open-Â­source implementation of the MPI message
    passing standard. It has been ported to many platforms and used by several vendors
    and research groups as the basis for their own MPI implementations. We are looking
    for collaboration at all levels of the software stack. Including, but not limited
    to, low-level networking libraries, shared memory, collective algorithms, performance
    testing/tuning, CI/CD, documentation, and more!
  Desired: C Python Shell Networking Linux/Unix
  Special: In-Person Only
- "\uFEFFSubmission": strack181s1
  Status: Accept
  Name1: Samuel
  Name2: Reeve
  Email1: reevest@ornl.gov
  Institution: Oak Ridge National Laboratory
  Title: Particle-based performance comparisons with Cabana
  Field: Materials science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: Particles (just points in a box) can be used to simulate a huge range
    of different processes and phenomena, from atoms to galaxies. Because there are
    so many similarities in writing simulation codes, improving the computational
    performance of those codes, and making sure the physics is correct (even with
    very different physics), we created a library to manage particles called Cabana.
    Cabana is made for high-performance computing (HPC) particle codes on all the
    hardware architectures (GPUs, etc.) across Department of Energy (using the Kokkos
    and MPI libraries). This project would focus on comparing the performance of recent
    Cabana applications on HPC platforms (or even potentially building a new Cabana-based
    code for a method of interest). Recent codes have focused heat transport, fracture
    and failure in materials, plasma physics, cosmology, and atomic behavior.
  Desired: Any programming (especially C++) experience would be highly useful; interest
    in GPU computing (especially Kokkos); experience or interest in materials (from
    any background or domain science)
  Comments1: I started at a national lab as a summer undergraduate student and I love
    continuing to work with students as a staff member!
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack182s1
  Status: Pre-Match+Workshop
  Name1: Damian
  Name2: Rouson
  Email1: rouson@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Deep learning for climate simulation
  Field: Artificial intelligence
  Topics: High-Performance Computing; Machine Learning and AI
  Abstract: The goal of this project is to use language-based parallel and GPU programming
    to accelerate neural-network training and large-batch inference in the context
    of developing a proxy application for the cloud microphysics component of a climate
    model.
  Desired: Programming in modern Fortran. Deep learning. Parallel or GPU programming.
  Special: U.S. Citizen Only; Permanent Resident OK; International OK; other
  Other: in-person or hybrid work preferred
- "\uFEFFSubmission": strack183s1
  Status: Pre-Match+Workshop
  Name1: Paul H.
  Name2: Hargrove
  Email1: phhargrove@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: UPC++/GASNet for lightweight communication and global address space support
  Field: programming models, languages and libraries for high-performance computing
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: Scientists use supercomputers to tackle some of the most challenging problems,
    ranging from biomedical simulations of COVID-19 spread in human lungs, to performing
    metagenome assembly based on environmental samples as a way to study climate change.
    The UPC++ library is used in both of these applications. We seek application and
    library developers to partner with our team, which develops parallel programming
    models such as UPC++ and GASNet-EX. These enable computational scientists across
    a broad range of disciplines to write high-performing, maintainable, parallel
    software for large-scale systems. If you are writing a parallel scientific application
    in C++, we would be glad to explore with you whether UPC++ could help with some
    of the more challenging aspects of your problem. UPC++ excels at handling applications
    and libraries that have challenging load balancing issues and irregular communication
    patterns. If your parallel program currently runs only in shared memory and you
    are interested in scaling up to larger, distributed-memory systems, we can help
    determine a path toward scalable performance on larger systems using UPC++.
  Desired: Parallel programming in C++
  Comments1: Berkeley has beautiful weather, scenic views and surfing nearby. Additionally
    our group has been geographically distributed since before it was cool so we know
    how to collaborate remotely and productively. So, regardless of whether you elect
    to relocate to Berkeley or not, you'll have a great experience.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack184s1
  Status: Accept
  Name1: Dan
  Name2: Gunter
  Email1: dkgunter@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Scientific Software
  Field: Computer Science
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); Machine Learning and AI
  Abstract: Diverse opportunities in the areas of software engineering, UX design
    research and implementation, and Python programming for Chemical and Environmental
    Engineering applications involving surrogate modeling and equation-oriented optimization
    application frameworks.
  Desired: Python programming or UI/UX knowledge or interest or software or release
    engineering or optimization applications; also any interest in documentation or
    Jupyter Notebook enhancements
  Special: International OK
- "\uFEFFSubmission": strack185s1
  Status: Pre-Match+Workshop
  Name1: Kevin A.
  Name2: Brown
  Email1: kabrown@anl.gov
  Institution: Argonne National Laboratory
  Title: Investigating and Optimizing Supercomputer Network Performance
  Field: Computer Science
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); High-Performance Computing;
    Machine Learning and AI
  Abstract: Supercomputers use the fastest network and storage technologies to help
    solve big problems in artificial intelligence (AI) and climate science among other
    fields. However, properly configuring supercomputers requires carefully tuning
    the hardware and software to meet the performance needs of the work to be done.
    Projects ideas include creating new software to measure performance on supercomputers,
    analyzing and optimizing the performance of climate science and AI applications,
    investigating and simulating new supercomputer designs, and improving discrete
    event simulations.
  Desired: Specific background depends on the specific project focus. Generally, experience
    with C or Python may help along with an interest in problem solving
  Comments1: This is a placeholder for a range of project ideas in the area of performance
    analysis, network simulations, and supercomputer designs. We can come up with
    specific projects based on your skills and interests.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack186s1
  Status: Accept
  Name1: Silvio
  Name2: Rizzi
  Email1: srizzi@anl.gov
  Institution: Argonne National Laboratory
  Title: Enabling Scientific Discovery With Supercomputers
  Field: Computer Science
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization)
  Abstract: As the first exascale supercomputers come online, scientists are confronted
    with formidable challenges in analyzing the outcomes of large-scale numerical
    simulations. I am actively seeking enthusiastic students and faculty members who
    share a deep interest in exploring the intricacies of supercomputer simulations.
    Together, we will leverage leading-edge technologies for scientific visualization
    and analysis to facilitate scientific discoveries.
  Desired: Experience in programming languages, such as C, C++, or Python. Experience
    in Computer Graphics and/or Machine Learning Frameworks is a plus.
  Special: other
  Other: would prefer no restrictions
- "\uFEFFSubmission": strack187s1
  Status: Accept
  Name1: Thomas
  Name2: Smith
  Email1: tmsmith@sandia.gov
  Institution: Sandia National Laboratories
  Title: High-Fidelity Computational Electromagnetics and Plasma Modeling
  Field: Computational EM Plasma Science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing; Machine Learning and AI
  Abstract: 'Computational electromagnetics and plasma physics (CEMP) are two areas
    of computational science that combine classical physics with high performance
    computing (HPC) to solve important national level problems. CEMP is a frontier
    in computational science requiring a great deal of discovery. The push to deliver
    fusion energy is growing, and at the national laboratories, universities and private
    sector, CEMP is playing an increasingly important role and will continue to do
    so. The project is centered around several fundamental concerns in CEMP. The first
    concern relates to verification of existing CEMP codes and asks the question "Is
    the code correct?" We use various numerical analysis techniques to answer this
    question including: developing analytic model problems from classic solutions,
    and constructing surrogate models that bridge gaps between theory and CEMP codes.
    We then run the CEMP on HPC systems to establish code credibility. The second
    concern relates to validation of CEMP codes and asks the question "Is our model
    correct?" To answer this question, we run sub- and system level simulations using
    HPC and use available data to determine how our CEMP solutions match up and address
    any gaps found in our modeling.'
  Desired: Training in mathematical physics and/or engineering (e.g., calculus, electromagnetics,
    fluid dynamics, computational fluid dynamics, plasma physics), A familiarity with
    programming in python and/or C++ is desired but not necessary, A familiarity with
    the Linux operating system
  Comments1: No formal training in plasma physics is necessary Interest in discovering
    how things work and how to solve difficult problems on a computer is important
  Special: Minimum GPA (specify what GPA in comments below); U.S. Citizen Only
  Comments2: 'Intern will be required to gain access to our secure network, minimum
    GPA: 3.0'
- "\uFEFFSubmission": strack188s1
  Status: Accept
  Name1: Meifeng
  Name2: Lin
  Email1: mlin@bnl.gov
  Institution: Brookhaven National Laboratory
  Title: Exascale Computing for High Energy Physics - Addressing the Portability Challenge
  Field: High Performance Computing, Physics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing
  Abstract: Computing plays an essential role in High Energy Physics (HEP) research.
    From the ab initio theory calculations using numerical techniques such as lattice
    QCD, to detector simulations and data analysis for the particle physics experiments
    such as those at the Large Hadron Collider, the computational demand has been
    growing rapidly due to the increased, exabyte-scale, data volume from the experiments
    and enhanced precision needed to probe new physics beyond the Standard Model.
    The exascale massively parallel supercomputers hold the promise to provide orders
    of magnitude more computing power to support this fundamental physics research.
    However, the diverse heterogenous architectures in the exascale systems present
    many challenges to the scientific software developers. This SRP project will develop
    and benchmark mini code examples based on the use cases we have extracted as part
    of the High Energy Physics Center for Computational Excellence project (www.anl.gov/hep-cce).
    The goal is to use these "mini-apps" to track the progress of the software stack
    to support performance portability, the notion that a single source code can run
    efficiently on multiple architectures, and the ways to address it. The participants
    will be exposed to both the physics motifs and computational challenges in high
    energy physics.
  Desired: Computer Science C++ Programming High Performance Computing Physics
  Comments1: The project can be tailored depending on the participant's experience
    and interests. And we fully expect the SRP participants to be actively engaged
    with the HEP-CCE team.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack189s1
  Status: Pre-Match+Workshop
  Name1: Arvind
  Name2: Mohan
  Email1: arvindm@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Machine Learning for Surrogate Modeling in Earth Sciences
  Field: Machine Learning and Physical Sciences
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Machine Learning and AI
  Abstract: Climate change is already causing more frequent and severe extreme weather
    events, such as hurricanes, floods, droughts, and wildfires. These events can
    have devastating impacts on communities, livelihoods, and infrastructure. Machine
    learning has become an attractive alternative to developing fast surrogate models
    of these phenomena. ML surrogate models can help decision-makers better understand
    and respond to these events and mitigate their consequences. To be valid, these
    models need to a) Predict the likelihood and severity of future climate disasters
    and b) Assess the vulnerability of communities and infrastructure to climate disasters.
    c) Be robust and reliable for trustworthiness. However, there are many fundamental
    challenges to making ML models helpful in this area, and the summer project will
    focus on developing methods to address this issue. The topic is open-ended, and
    the student will have the opportunity to pick a specific direction of their liking.
  Desired: 1) Experience and knowledge of fluid mechanics and turbulence. 2) Good
    understanding of partial and ordinary differential equations 3) Experience with
    neural networks is desired.
  Special: In-Person Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack191s1
  Status: Pre-Match+Workshop
  Name1: Rafael
  Name2: Zamora-Resendiz
  Email1: rzamoraresendiz@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Scaling Protein Structure Machine Learning Applications Using HPC
  Field: Computational Biology
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing;
    Machine Learning and AI
  Abstract: Graph convolution and self-attention deep learning models have grown in
    popularity in the domain of proteomics. These machine learning approaches have
    been used in several proteomic problems including protein classification and protein-ligand
    binding affinity prediction. Searching for ligands and poses with high binding
    affinity have immediate applications in drug design and drug repurposing. While
    many DL tools have been used to model the site interaction at the residue level,
    atom-level models would effectively increase the resolution of interactions. Even
    so, scaling to systems with &gt;1,000 atoms is a non-trivial task which requires
    HPC. Recently, much work has gone into scaling training of language model architecture
    like GPT and BERT using HPC. The proposed project will explore utilizing language
    model architectures to scale the modeling of protein structures in the context
    of protein-ligand binding. Model parallelism will be used to enable modeling of
    proteins at the atomic level. After training on large datasets of binding site
    interactions, these models will be tested against out-of-training examples to
    observe its utility in imputing binding affinities across diverse protein and
    ligand databases. Methods for interpreting model parameters will be developed
    to provide biological meaningful insights that can help in drug design and repurposing.
  Desired: 'Relevant Skills, Background or Interests: Good understanding of programming
    and machine learning. Some understanding of parallel programming and working with
    high performance computing systems. Interested in the application of computational
    skills to the domain of biology and medicine. A deep desire towards improving
    their skills of writing well-documented and reusable scientific code.'
  Special: U.S. Citizen Only
- "\uFEFFSubmission": strack192s1
  Status: Accept
  Name1: Patricia
  Name2: Gonzalez-Guerrero
  Email1: lg4er@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Beyond moore computer architectures
  Field: Computer architecture
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing; Machine Learning and AI
  Abstract: 'Project 1: FPGA based architecture exploration. We use FPGAs to evaluate
    architectural features that could improve performance in scientific computing.
    We then can take the FPGA tested architecture and generate ASICs. Project2: We
    propose to explore temporal computing, stochastic computing, or deterministic
    streams for more efficient computing. Project3: We propose to explore superconducting
    computing for low power high performance computing.'
  Desired: 'One of below: circuit design Computer architecture Signal processing'
  Special: other
  Other: none
- "\uFEFFSubmission": strack193s1
  Status: Pre-Match+Workshop
  Name1: Victor
  Name2: Mateevitsi
  Email1: vmateevitsi@anl.gov
  Institution: Argonne National Laboratory
  Title: Digital Twins
  Field: Digital Twins
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); High-Performance Computing
  Abstract: Robotics is changing the way new technologies are manufactured, researched,
    and developed. Robots can operate at high speed, with infinite precision, and
    without fatigue. Thus, they are ideal for repetitive work in hazardous environments
    like nuclear reactors. However, designing and evaluating such systems is extremely
    hard. A digital twin is a digital replica of the physical environment, the mechanical
    components, and the entire research/production workflow. You can think of a digital
    twin as a digital reconstruction of the lab, including all robotic arms, sensors,
    desks, laboratory components, tests, and how they interact with each other. Our
    research interests include exploring how digital twins can help diagnose operational
    anomalies, understand system health, and improve overall system efficiency in
    Virtual Reality. Imagine a nuclear physicist wearing a Virtual Reality headset
    and safely assembling a novel nuclear reactor inside a Virtual Environment. They
    can now run tests and simulations, gather sensor data, and improve their design.
    Once they are satisfied with the results, they can request the physical replica
    of the robotic laboratory to assemble the reactor and perform the pre-programmed
    tests.
  Desired: Augmented/Virtual Reality Robotics
  Special: In-Person Only
- "\uFEFFSubmission": strack194s1
  Status: Pre-Match+Workshop
  Name1: Johannes
  Name2: Blaschke
  Email1: jpblaschke@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Workflow enablement on HPC
  Field: Computing
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); High-Performance Computing
  Abstract: 'This project explores various workflow technologies, and how they might
    be used on a Supercomputer at NERSC. Future Supercomputers will offer a broad
    range of capabilities at NERSC Examples relevant to scientific workflows on the
    include: simulation performance, data movement and management, application of
    machine learning, organization and composition of complex computational tasks,
    interaction with external resources beyond the NERSC data center (e.g. edge, cloud,
    and cross-facility). We will be working on developing benchmarks and test cases
    for a range of workflow technologies, depending on the applicant''s field of study
    and personal interest. Some example focus areas are: 1. Exploring use cases for
    workflow managers, eg: Fireworks, Snakemake, Parsl, etc 2. Exploring non-MPI communication
    libraries, eg. Distributed.jl, Legion, etc 3. Exploring new storage technologies
    and tools'
  Desired: 'Experience with: 1. Linux / Git 2. Compiling software (with Make and CMake)
    and managing shell environments 3. Some basic programming skills in C, Rust, Julia,
    and/or Python are a must. Depending on the focus area, applicants should have
    a strong interest in scientific software workflows for HPC systems.'
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack195s1
  Status: Accept
  Name1: Robert
  Name2: Jacob
  Email1: jacob@anl.gov
  Institution: Argonne National Laboratory
  Title: Global Climate Modeling
  Field: Climate, HPC
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: My group is part of a multi-lab collaboration to develop a global climate
    model that runs well on DOE's most advanced computing facilities. We are involved
    in all aspects of the software development of the model and its performance on
    heterogeneous architectures. We also develop python tools for analyzing the data.
    Join our group if you are interested in any of these topics.
  Desired: 'Any of: high performance computing, research software engineering, data
    analysis, performance engineering.'
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack196s1
  Status: Accept
  Name1: Justin
  Name2: Wozniak
  Email1: woz@anl.gov
  Institution: Argonne National Laboratory
  Title: HPC Workflow Performance
  Field: HPC, Workflows
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software)
  Abstract: 'High Performance Computing (HPC) workflows combine physical simulations
    with machine learning and other analysis to address scientific problems in modeling
    the spread of COVID-19, designing precision cancer treatments, and other areas.
    The Swift/T workflow language is designed to run on the largest available supercomputers
    and integrate complex, parallel software packages under the control of a high-level
    dataflow language. Optimizing and debugging such workflows is difficult. There
    are range of tools developed by the computer science community to analyze the
    performance and correctness of such software systems. In this project, the team
    will apply one or more such systems to Swift/T workflows in a scientific application
    area. The team will run Swift/T in a simulated environment using a distributed
    computing simulator such as SimGrid/SMPI to evaluate correctness and performance.
    Technical details: Swift/T is a parallel programming language that uses a Java-based
    programming language translator to generate code for a C and MPI -based runtime.
    Swift/T can distributed and run user scientific codes written in any language,
    but Python and R modules are a popular choice. The system is an excellent environment
    in which to learn about programming language design/implementation, distributed
    computing, and systems software in general.'
  Desired: C language and Linux environment.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack197s1
  Status: Accept
  Name1: Natalie
  Name2: Isenberg
  Email1: nisenberg@bnl.gov
  Institution: Brookhaven National Laboratory
  Title: Modeling and Control of Particle Accelerator Beams using Bayesian Neural
    Networks
  Field: Surrogate modeling/AI/ML
  Topics: Machine Learning and AI
  Abstract: 'Particle accelerators are a central tool for scientific discovery, from
    unraveling the governing laws of fundamental particles, to understanding the universe''s
    origins. Brookhaven National Laboratory is home to the Relativistic Heavy Ion
    Collider (RHIC) and the future Electron Ion Collider (EIC), two world-leading
    particle accelerators. At RHIC, which is the largest particle accelerator in the
    United States, scientists are currently studying the properties of subatomic particles.
    Specifically, researchers use particle collisions to recreate extreme conditions
    like those shortly after the Big Bang: the prevailing theory for the origins of
    our universe. Both cutting-edge accelerator experiments rely on complex particle
    beam controls (e.g., altering trajectories) to create collisions that generate
    useful data. Ensuring the accuracy and reliability of particle collision experiments
    is of critical importance and requires the development of robust beam control
    methodologies. In this research project, we will build a data-driven model of
    beam position using Bayesian neural networks (BNNs). BNNs are machine learning
    models that provide accurate predictions while also quantifying the error inherent
    in the data, ensuring robust and reliable beam position forecasts. The student
    intern working on this project will gain practical experience in cutting-edge
    machine learning topics as applied to a real high-energy physics application.'
  Desired: Some experience in Python or Julia preferred, but not required.
  Special: In-Person Only; Permanent Resident OK; International OK
- "\uFEFFSubmission": strack198s1
  Status: Accept
  Name1: Neil
  Name2: Getty
  Email1: ngetty@anl.gov
  Institution: Argonne National Laboratory
  Title: Vision Language Action Models for Robotic Surgery
  Field: AI, Robotics, LLM, Medicine
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); Machine Learning
    and AI
  Abstract: Robotic surgery presents many motivating challenges for computing research.
    Robotic surgery is an interface between surgeons and patients, much in the way
    motor vehicles are becoming less mechanic, and more of an interface between drivers
    and the road. In driving, optical and radar sensors coupled with automated warning,
    braking, and steering actions have dramatically increased motor-vehicle safety.
    We expect a similar development of technologies that prevent mistakes and improve
    outcomes in surgery. We are partnered with the Surgical Innovation and Training
    Lab at the University of Illinois at Chicago, with access to a robotic surgery
    research kit, expert annotated surgery videos, and medical expert collaborators.
    Our research efforts include instrument detection and segmentation, depth estimation,
    instrument tracking and kinematic estimation, and skill estimation applied to
    robotic surgery. We are particularly interested in exploring foundation models,
    vision language, and vision language action models for robotic surgery tasks.
  Desired: Programming (python, pytorch, cv2), data, machine learning, deep learning,
    biomedicine, computer vision
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack199s1
  Status: Accept
  Name1: Carlos Fernando
  Name2: Gamboa
  Email1: cgamboa@bnl.gov
  Institution: Brookhaven National Laboratory
  Title: Data Storage for Scientific Experiments
  Field: Distributed Data Systems
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization)
  Abstract: One of the missions of the Scientific Data and Computing Center (SDCC)
    at Brookhaven National Laboratory is to provide access to storage services for
    a diverse range of High Energy Physics (HEP) scientific experiments, including
    LHC-ATLAS[1], Belle2[2], and DUNE[3]. An aggregate of 222 million files and data
    storage totaling 76PB is distributed and managed by independent storage instances
    for each Virtual Organization (VO). The underlying technology used to support
    this storage is dCache [4]. Currently, we are in the process of evolving and reviewing
    event visualization and control schemes, as well as log analysis tools, to improve
    analytics and monitoring and ensure the high availability of this storage service.
    Additionally, we are interested in identifying state-of-the-art tools and techniques
    that allow us to anticipate or predict inefficient storage resource access or
    real time system component failures. Ultimately, these improvements will have
    a significant impact on advancing scientific discovery while optimizing storage
    resources. [1] https://home.cern/science/experiments/atlas [2] https://www.belle2.org
    [3] https://www.dunescience.org [4] https://www.dcache.org
  Desired: 'Knowledge of: -Scripting languages like Python -Programing languages like
    Java -Operational Systems like Linux -Databases (Relational or non) -Document
    databases like Elasticserach -Artificial Intelligence techniques'
  Special: U.S. Citizen Only; Permanent Resident OK
- "\uFEFFSubmission": strack200s1
  Status: Accept
  Name1: Allison
  Name2: Aiken
  Email1: aikenac@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Aerosol Science
  Field: Earth and Environmental Science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); Machine Learning
    and AI
  Abstract: Aerosols are small particles (&lt;~10 microns in diameter) that are suspended
    in a gas, like the Earthâ€™s atmosphere. These particles are central to understanding
    the water cycle and transport of nutrients within the Earth System. A complete
    understanding cannot be provided without ground-based and vertically resolved
    observations, particularly for aerosol-cloud interactions. The goal of this study
    is to analyze diverse and large datasets collected by the U.S. DOE Atmospheric
    Radiation Measurement (ARM) mobile facility during campaigns that we have deployed
    instrumentation to and are actively involved in with funding from the Atmospheric
    System Research (ASR). Two examples include the Surface Atmosphere Integrated
    Field Laboratory (SAIL) campaign in Colorado focused on aerosol impacts on mountain
    hydrology and the Eastern Pacific Cloud Aerosol Precipitation Experiment (EPCAPE)
    in California focused on aerosol-cloud interactions. Data includes but are not
    limited to those collected by the Aerosol Observing System (AOS) and the tethered
    balloon system (TBS). Specific aims are directed at answering key aerosol process
    science objectives related to identifying different aerosol regimes, the processes
    controlling their lifecycles, quantifying impacts on the radiative budget, and
    the sensitivity of cloud phase and precipitation to cloud condensation nuclei
    (CCN) and ice-nucleating particle (INP) concentrations.
  Desired: 'Desired relevant skills include: experience and/or exposure to different
    computing languages, e.g., Python, Igor, R, JupyterHub, etc. as well as applying
    and/or developing statistical and mathematical algorithms, e.g., positive matrix
    factorization, K-means clustering, machine learning/AI, etc. Examples of desired
    interests include but are not limited to: large data science, environmental science,
    atmospheric science, high-time resolution measurements, chemistry and mass spectrometry,
    physics/optics, single-particle measurements, climate science.'
  Special: other
  Other: None known.
- "\uFEFFSubmission": strack202s1
  Status: Accept
  Name1: Jay
  Name2: Lofstead
  Email1: jay@lofstead.org
  Institution: Sandia National Laboratories
  Title: Accelerating Scientific Insights Through Advanced Data Exploration
  Field: computer science, computational science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Computer Science (i.e.,
    architectures, compilers/languages, networks, workflow/edge, experiment automation,
    containers, neuromorphic computing, programming models, operating systems, sustainable
    software); High-Performance Computing
  Abstract: Large scale science simulations and observations both generate enormous
    data volumes that must be analyzed to generate scientific insights. Sometimes,
    this analysis are simple min/max to support visualization. Other times, they are
    complex or derived quantities. For example, an air pressure gradient can show
    both a hurricane as well as straight-line winds. Being able to query for places
    where the gradient meets criteria is more general and helpful when looking for
    severe weather events. This work will help support managing these derived quantities
    as well as supporting the query operations. No prior knowledge of the mathematical
    operations nor special machine learning or database skills required. Some exposure
    to ease on the job learning is desired.
  Desired: basic database, basic machine learning
  Special: In-Person Only
- "\uFEFFSubmission": strack203s1
  Status: Accept
  Name1: Rajshree
  Name2: Deshmukh
  Email1: rajshreed@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: User experience design &amp; development for Science softwares
  Field: User Experience Design, Web development
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization)
  Abstract: The student will work on interface design and development for a particular
    scientific application. This opportunity will give hands on experience of ideating
    on complex user needs in research domain and coming up with solutions.
  Desired: Students with interests in user experience design, data visualization,
    web development can apply
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack204s1
  Status: Accept
  Name1: Paul
  Name2: Hovland
  Email1: hovland@mcs.anl.gov
  Institution: Argonne National Laboratory
  Title: ML-based compression for derivative computation
  Field: Automatic differentiation
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Machine Learning and AI
  Abstract: Efficient computation of derivatives for both computational science and
    machine learning applications often relies on the so-called reverse mode of automatic
    differentiation (autodiff). Unfortunately, reverse-mode autodiff requires saving
    many intermediate states, which can lead to substantial memory or storage requirements.
    This project will investigate whether lossy compression techniques based on machine
    learning can be used to compress this data and reduce memory requirements while
    maintaining suitable levels of accuracy in the derivative computations.
  Desired: Basic understanding of derivatives (first semester calculus) Programming
    in python or a related language Interest in machine learning
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack205s1
  Status: Accept
  Name1: Tim
  Name2: Waters
  Email1: waters@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Radiation-MHD modeling of accreting black holes
  Field: Magnetohydrodynamics and radiation hydrodynamics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: I am interested in pursuing collaborations to work on topics in radiation-MHD
    modeling for black hole astrophysics. Specific projects include deriving dispersion
    relations for the linearized radiation-MHD equations, calculating the observables
    obtainable from reverberation mapping campaigns, modeling outflows in low-mass
    X-ray binaries, and modeling accretion flows around supermassive black holes.
    These projects range from semi-analytic, requiring only knowledge of basic complex
    function theory and python programming, to fully numerical, requiring knowledge
    of C++ and high-performance computing.
  Desired: Python or C++ programming, courses on plasma physics or MHD, experience
    running hydrodynamical simulations, interest in learning high performance computing.
  Special: In-Person Only; Permanent Resident OK
- "\uFEFFSubmission": strack206s1
  Status: Accept
  Name1: William
  Name2: Godoy
  Email1: godoywf@ornl.gov
  Institution: Oak Ridge National Laboratory
  Title: Exploring HPC+AI workflows in Julia
  Field: High-performance computing
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing
  Abstract: We plan to explore the use of the Julia programming language on constructing
    high-performance computing (HPC) and AI workflows. We look towards the advancement
    of HPC software by incorporating a unifying high-level and high-performance Julia
    language as a scientific layer. We will explore cases on Frontier and Summit (if
    available).
  Desired: High-performance computing Programming Data analysis AI Scientific Software
  Special: In-Person Only; International OK
- "\uFEFFSubmission": strack207s1
  Status: Pre-Match+Workshop
  Name1: Sandeep
  Name2: Madireddy
  Email1: smadireddy@mcs.anl.gov
  Institution: Argonne National Laboratory
  Title: Probabilistic Machine Learning for Scientific Data
  Field: Scientific Machine Learning
  Topics: Machine Learning and AI
  Abstract: 'ome unique challenges in scientific data that needs to be considered
    while building data-driven models are: (1) noise and uncertainty, (2) data scarcity,
    and (3) large feature spaces. Probabilistic models are a natural choice to address
    many of these challenges and provide a systematic approach to reason about the
    prediction uncertainty. Historically, the adoption of probabilistic modeling approaches
    has been limited by the scalability of the inference approaches. With the recent
    advances in Bayesian deep learning, approximate inference approaches and their
    information-theoretic connections have enabled inference on large-scale (with
    millions of parameters) models efficiently with modest computational requirements,
    obtaining state-of-the-art predictive accuracy. This project would involve building
    such probabilistic deep learning models for applications such as equilibrium reconstruction
    of plasma profiles in a magnetically confined fusion tokamak and detecting strong
    gravitational lenses from astronomical observations from telescopes.'
  Desired: Python programming, applied mathematics/statistics
  Special: other
  Other: None
- "\uFEFFSubmission": strack208s1
  Status: Accept
  Name1: Kibaek
  Name2: Kim
  Email1: kimk@anl.gov
  Institution: Argonne National Laboratory
  Title: Federated Learning at Edge
  Field: machine learning, edge computing
  Topics: Machine Learning and AI
  Abstract: Federated learning (FL) is a method where multiple devices train machine
    learning models locally on their own data, and then collaboratively refine a shared
    model by exchanging updates, without directly sharing the actual data. This project
    aims to address the technical challenges by developing and deploying FL models
    to the edge devices available through Argonne National Laboratory. Closely working
    with multiple scientists at the lab, the participants will develop, analyze, and
    test the FL model and training algorithms on high-performance computing cluster
    first and then on the edge devices.
  Desired: Experience with python, PyTorch, machine learning.
  Special: In-Person Only; International OK
- "\uFEFFSubmission": strack209s1
  Status: Accept
  Name1: Wibe Albert
  Name2: de Jong
  Email1: wadejong@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Enabling scientific discovery with HPC, AI and Quantum
  Field: AI and Quantum
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing;
    Machine Learning and AI; Quantum Computing and Information Science
  Abstract: One of the big challenges in finding new molecules that can better capture
    solar energy, to design molecular crystals that can better capture CO2 from the
    air, or materials that can convert heat into electricity is the very large search
    space of possibilities. We can accelerate this search with AI and machine learning
    methods that allow us to quickly determine if a molecule or material has the desired
    properties, and if it can be made, but this search can still take forever. We
    have been developing approaches for inverse design. Projects can involve the further
    development of our inverse design methods, or exploring our tools for real science
    questions. Quantum computing has received a lot of attention. We now have noisy
    quantum computers online on which we can do actual experiments. Our projects range
    from developing algorithms and simulation approaches that translate scientific
    problems we run on classical computers to problems that can be run on quantum
    computers...and we run them on quantum computers to get scientific results.
  Desired: For AI related research, some understanding of machine learning approaches
    and some cursory reading of the literature with respect to inverse design for
    chemistry and materials. For quantum related research, a basic understanding of
    quantum computing would be a benefit. Reading one of the popular quantum computing
    books, for example the first parts of Nielsen and Chuang (Quantum Computation
    and Quantum Information), and doing some of the online qiskit tutorials will give
    you a great head start.
  Special: In-Person Only
- "\uFEFFSubmission": strack210s1
  Status: Accept
  Name1: Cody
  Name2: O'Donnell
  Email1: ctodonnell@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: User Experience for Scientific Software Applications
  Field: UX/UI Design and Development
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization)
  Abstract: User experience design is frequently an afterthought for scientific software
    applications. Nonetheless, the actual experience a person has while using a piece
    of software can often make or break its success. Our team is working to make sure
    that every scientific team has the ability to build software applications that
    are intelligently designed, highly usable, and effective for its users. We are
    in the process of building a suite of design and software tools that break scientific
    processes into their most repeatable components and task flows. The goal is for
    these components and task flows to be the building blocks for new scientific applications.
    This means we are building both visual designs and actual code that teams will
    base their applications around. These tools have the potential to transform the
    way scientific teams approach the design of software and user interfaces. We are
    working with people from a breadth of scientific areas because these tools are
    meant to span the whole scientific domain. For example, we are or will be collaborating
    with teams in environmental science, water optimization, materials science, genomics,
    computer science, and physics.
  Desired: 'Interested in: Web development, user interface design, JavaScript, React,
    software development, user experience research, data visualization, information
    architecture'
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack211s1
  Status: Accept
  Name1: Meng
  Name2: Meng
  Email1: mengm@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Mentor students
  Field: Rock mechanics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); High-Performance Computing
  Abstract: My expertise covers advanced multi-physics geomechanics testing, well
    integrity, cement materials, poromechanical modeling, and data analysis. With
    these skills, I have participated in many different projects, including well integrity
    and stability for geothermal and CCUS, wellbore and reservoir stimulation for
    geothermal and unconventional, injection induced seismicity for geothermal and
    carbon sequestration, and data analysis for CCUS. I believe there are still lots
    of opportunities for Petroleum Engineering with application to the energy transition.
  Desired: I hope to work with students with rock mechanics, petroleum, civil, mathematics,
    and mining background. If the students are interested in geothermal and carbon
    sequestration, we can find more topics to work on.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack214s1
  Status: Accept
  Name1: Nirmal
  Name2: Prajapati
  Email1: prajapati@lanl.gov
  Institution: Los Alamos National Laboratory
  Title: Extreme scale computing through co-design of applications, algorithms, and
    architectures
  Field: compilers/languages/architectures/modeling
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); High-Performance Computing; Machine
    Learning and AI
  Abstract: Lead scientific simulations at extreme scale through the co-design of
    applications, algorithms, and architectures. Deliver solutions for multiple science,
    engineering, and security missions including the development of methods for large-scale
    high performance computing applications. Work on a wide array of scientific problems
    ranging from weapons research and algorithmic co-design to compiler technologies
    and machine learning that enable scientists to concentrate on science rather than
    programming. Develop scientific software frameworks that are performance portable
    for different HPC architectures. Implement high-performing versions for important
    applications at the lab. Profile CPU/GPU (Graphics Processing Unit) codes, identify
    bottlenecks, improve the performance of applications using optimization techniques.
    Investigate and prototype performance improvements along with verification of
    outputs. Run codes on LANLâ€™s cluster and/or non-LANL supercomputers. Write codes
    in Python, C/C++ and CUDA (language for programming GPUs) and/or HIP (language
    for AMD GPU architectures). Use profiling tools, applied machine learning techniques
    and code transformations to improve the performance of applications.
  Desired: Some background or coursework in applied machine learning, code transformations,
    compilers, programming languages, performance optimization, parallel processing
    is preferred. Desired skills include LLMs, CNN, Python, C/C++, CUDA, OpenMP, etc.
    but not required.
  Special: Minimum GPA (specify what GPA in comments below); International OK
  Comments2: 3.0 or above
- "\uFEFFSubmission": strack215s1
  Status: Accept
  Name1: Oliver
  Name2: Ruebel
  Email1: oruebel@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: AI for protein structure prediction and analysis
  Field: Computational biosciences and machine learning
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); Machine Learning
    and AI
  Abstract: The goal of this project is to enhance the analysis and prediction of
    protein structures from sequence and experimental data.
  Desired: Machine learning Protein structure analysis
  Special: In-Person Only
- "\uFEFFSubmission": strack220s1
  Status: Accept
  Name1: Talita
  Name2: Perciano
  Email1: tperciano@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Probabilistic Graphical Deep Learning Field
  Field: Quantum computing, computer science
  Topics: Machine Learning and AI, Data Science (i.e., data analytics, data management
    &amp; storage systems, visualization); Machine Learning and AI; Quantum Computing
    and Information Science
  Abstract: A graphical model or probabilistic graphical model (PGM) or structured
    probabilistic model is a probabilistic model for which a graph expresses the conditional
    dependence structure between random variables. They are commonly used in probability
    theory, statisticsâ€”particularly Bayesian statisticsâ€”and machine learning.
    One of the main advantages about this techniques is its ability to use prior information
    (physical constraints) related to the data. This becomes very important when analyzing
    scientific data. This project aims to develop efficient PGM-based algorithms to
    tackle problems such as image segmentation, image denoising, feature tracking,
    data reduction, data fusion, etc. We use mainly Markov Random Fields and Conditional
    Random Fields, and some of our approaches combine these methods with deep learning
    algorithms. Quantum computing is a research area that has received a great amount
    of attention in the last few years. In this project, we aim to take advantage
    of quantum computing theory to develop quantum data analysis and quantum machine
    learning tools suitable to the analysis of scientific data. This includes the
    development of new quantum circuits for quantum data representation and for analysis
    algorithms (feature extraction, template matching). We also aim to develop innovative
    quantum machine learning algorithms targeting/combining NISQ devices and HPC.
    We aim to develop concrete proof-of-concept tools that run on NISQ devices.
  Desired: 'Related interests: Python and C++ programming languages, data analysis,
    statistics, applied mathematics, image processing, deep learning, machine learning.'
  Special: other
  Other: None
- "\uFEFFSubmission": strack221s1
  Status: Accept
  Name1: Anna
  Name2: Giannakou
  Email1: agiannakou@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Informing the next generation of HPC networking using intelligent data analytics
  Field: computer science, networking, machine learning
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); High-Performance Computing;
    Machine Learning and AI
  Abstract: Scientific discovery depends on analyzing large amounts of experimental
    data that are produced from different instruments scattered around the world.
    In the next 10 years the amount of experimental data produced is expected to increase
    by at least two orders of magnitude. In order to be analyzed, data needs to be
    transferred fast and reliably to HPC centers introducing network performance as
    a critical factor for success. In this project we will use data analysis combined
    with machine learning to detect data movement performance patterns that will inform
    the design of dynamic HPC networks. We will use scientific network traffic from
    NERSC, one of the leading HPC facilities in the world. In this project we are
    looking for someone to help us understand information from different sources and
    ultimately unveil the key to faster, next generation HPC networks.
  Desired: coding data analysis systems communication presentation
  Special: other
  Other: none
- "\uFEFFSubmission": strack222s1
  Status: Pre-Match+Workshop
  Name1: John
  Name2: Wu
  Email1: kwu@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Effective Data Management for Large Scientific Workflows
  Field: Data Management
  Topics: Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); Machine Learning and AI
  Abstract: The Scientific Data Management (SDM) research group is broadly interested
    in enabling and accelerating scientific discoveries through effective data management
    and analysis tools and libraries. The SDM groupâ€™s research and development efforts
    focus on (1) scalable storage and I/O strategies, (2) autonomous data management
    infrastructure, (3) data life-cycle management, and (4) workflow optimization
    and automation. Our group actively works with data generation and analysis workflows
    to reduce the complexity of large scientific analyses, including complex real-time
    workflows that could drive the next generation of scientific user facilities.
    Members of the SDM group work closely with application scientists throughout the
    DOE community, academic and industry researchers around the world. The group has
    a strong history of publications and contributes to many widely used software
    systems. We have strong contributions to well-known I/O libraries including HDF5
    and ADIOS; and are the primary developers of FastBit, FasTensor, and so on.
  Desired: "#NAME?"
  Special: In-Person Only
- "\uFEFFSubmission": strack227s1
  Status: Pre-Match+Workshop
  Name1: Silvia
  Name2: Crivelli
  Email1: sncrivelli@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Using AI and HPC for Healthcare and Precision Medicine
  Field: AI for science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); Machine Learning
    and AI
  Abstract: As part of our collaboration with the VA and DOE, we are currently using
    natural language processing to extract important life events from electronic health
    records that are correlated with high suicide risk. In this project, we are looking
    for a student intern that is interested in the cross-section of machine learning
    and healthcare that can help us develop a user-friendly interface for clinicians
    and researchers. Ideally, this UI will help accelerate better decision-making.
  Desired: Knowledge of programming, frontend UI development, data visualization,
    problem solving
  Special: other
  Other: none
  Comments2: none
- "\uFEFFSubmission": strack228s1
  Status: Accept
  Name1: Amal
  Name2: Gueroudji
  Email1: agueroudji@anl.gov
  Institution: Argonne National Laboratory
  Title: Performance Analytics of Dask Workloads
  Field: Computer science
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); High-Performance Computing
  Abstract: Dask is a task-based distributed Python framework with the unique feature
    of offering distributed versions of well-known libraries like NumPy, Pandas, and
    Scikit-learn. It has been utilized for high-performance data analytics within
    high-performance computing (HPC) workflows. While it boasts a strong performance
    record, it currently lacks an analysis of I/O performance, which is critical for
    HPC workloads. In this project, the selected student will utilize Darshan to extract
    and analyze I/O operations in Dask. The primary objectives are to gain an understanding
    of I/O performance and subsequently propose solutions for its improvement.
  Desired: Knowledge of distributed programming and data analytics is good, as well
    as curiosity to discover new topics and fields, in order to generate future research
    directions.
  Special: International OK
- "\uFEFFSubmission": strack229s1
  Status: Accept
  Name1: Maria
  Name2: Chan
  Email1: mchan@anl.gov
  Institution: Argonne National Laboratory
  Title: AIMaterials
  Field: Computational Materials Science
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization); High-Performance
    Computing; Machine Learning and AI
  Abstract: We use a combination of AI/ML and computational modeling to understand
    and design energy materials. In particular, we work on (1) predicting materials
    properties using a combination of first principles calculations and ML; (2) seeing
    materials changes in the nanoscale through interpreting x-ray and electron microscopy
    data; (3) using computer vision and language models to create intelligent knowledge
    extraction software. These approaches are applied towards energy storage, photovoltaics,
    or catalysis.
  Desired: 'Proficiency in Python programming is required. Knowledge of some of the
    following is beneficial: batteries, solar cell, catalysis, solid state physics,
    first principles or atomistic simulations, machine learning/artificial intelligence,
    computer vision, language models.'
  Special: Permanent Resident OK
- "\uFEFFSubmission": strack230s1
  Status: Accept
  Name1: Gunther
  Name2: Weber
  Email1: ghweber@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Visualization of Scientific Machine Learning Models
  Field: Data visualization; machine learning
  Topics: Data Science (i.e., data analytics, data management &amp; storage systems,
    visualization); High-Performance Computing; Machine Learning and AI
  Abstract: Scientific Machine Learning (SciML) is a growing research area that uses
    innovative machine learning solutions to obtain scientific insights from large
    data sets. Understanding these novel tools requires analyzing high-dimensional
    functions that have properties very different from those seen in other, more traditional
    DOE applications. For example, the features of a loss as a function of neural
    network (NN) weights provide valuable insights into properties of architectures
    that affect convergence during training. Compared to high-dimensional functions
    in other DOE-relevant applications, such as potential energy landscapes in chemistry,
    ML loss landscapes have many more dimensionsâ€”millions or billions of weights
    compared to tens or hundreds of degrees of freedom for molecules. Initial work
    within the ML community on visualizing loss landscapes has shown great promise,
    e.g., by relating NN architecture choices to the smoothness of the function being
    optimized during the learning process. More sophisticated visualization techniques
    can provide a much deeper understanding of the properties of NNs, which is particularly
    important for SciML problems. The goal of this project is to develop new visualization
    and data analysis approaches, e.g., based on topological data analysis, to help
    better understand these functions and as a result SciML models.
  Desired: data visualization, dimension reduction, multidimensional scaling, topological
    data analysis, machine learning, user interface design
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack232s1
  Status: Under Evaluation
  Name1: David I.
  Name2: Santiago
  Email1: david.i.santiago@lbl.gov
  Institution: Lawrence Berkeley National Laboratory
  Title: Experimental Quantum Computing
  Field: Superconducting Quantum Processors
  Topics: Quantum Computing and Information Science
  Abstract: We run a team where we design, fabricate, deploy superconducting quantum
    processors. We also use our processors to run state of the art quantum algorithms
    and protocols.
  Desired: Physics, quantum information science, strong knowledge of E&amp;M, computer
    programming, some knowledge of quantum mechanics
  Special: In-Person Only
- "\uFEFFSubmission": strack233s1
  Status: Pre-Match+Workshop
  Name1: Lavanya
  Name2: Ramakrishnan
  Email1: lramakrishnan@lbl.gov
  Title: Data lifecycle management
  Field: Computer science
  Topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
    experiment automation, containers, neuromorphic computing, programming models,
    operating systems, sustainable software); Data Science (i.e., data analytics,
    data management &amp; storage systems, visualization); High-Performance Computing;
    Machine Learning and AI
  Abstract: Automation, self-guiding and self-driving are increasingly using algorithm-driven
    adaptive measurements for operation of end-to-end workflow. There is a need for
    a number of AI techniques, workflow and data management techniques to develop
    the infrastructure.
  Desired: Computer science background with working knowledge of one or more of Python,
    ML/AI, Javascript, databases
  Special: International OK
- "\uFEFFSubmission": strack236s1
  Status: Accept
  Name1: Slaven
  Name2: Peles
  Email1: peless@ornl.gov
  Institution: Oak Ridge National Laboratory
  Title: Complex Systems
  Field: Computational Science
  Topics: High-Performance Computing
  Abstract: Develop scalable analysis methods for power systems that can perform exascale-level
    computations in support of grid planning and operation.
  Desired: C/C++, CUDA, HIP, Python, Numerical Linear Algebra, Numerical Integration,
    Statistical Analysis, Machine Learning, Power Systems, Power Electronics, or any
    combination of those skills.
  Special: Permanent Resident OK; International OK
- "\uFEFFSubmission": strack238s1
  Status: Accept
  Name1: Mark
  Name2: Taylor
  Email1: mataylo@sandia.gov
  Institution: Sandia National Laboratories
  Title: visualization for atmospheric simulation output
  Field: Atmospheric science, Computational science, Applied Mathematics
  Topics: Computational Science Applications (i.e., bioscience, cosmology, chemistry,
    environmental science, nanotechnology, climate, etc.); Data Science (i.e., data
    analytics, data management &amp; storage systems, visualization)
  Abstract: Produce visualizations from high resolution E3SM global climate simulations.
    Using python and matplotlib and large E3SM 3km global atmosphere data sets, Find
    interesting phenomena in the data sets, such as tropical cyclones, atmospheric
    rivers and mesoscale cloud systems. Plot various fields such as total water content,
    precipitation rate, cloud reflectivity, superimposed on images of the earth showing
    oceans and land masks. Generate high resolution publication quality images and
    animations suitable for use in journal articles, presentations and E3SM publicity.
  Desired: Some programming experience in a high level language (python, matlab),
    linear algebra or numerical linear algebra, interest in linux command line work.
    Interest in learning python-based visualization libraries (matplotlib, holoviz)
  Special: Permanent Resident OK
