Submission,Status (This Stage),First/Given Names (first),Last/Family Name (first),Email (first),Company/Institution (first),Department (first),Photograph (first),Website (first),SRP Project Title (first),What is the NAIRR Project Name? (first),What is the HPSF Project Name? (first),Please select all the topical areas that apply to your project: (first),Brief Abstract (200 words) (first),"Desired relevant skills, background, or interests (don't be too prescriptive) (first)",Any other comments (first),Lightning Talk Title (Maximum 10 words),Keywords (Maximum 20 words),Biography (Maximum 200 words)
proj102s1,Accept Wave 2 (Confirmed),Shu,Hu,hu968@purdue.edu,Purdue University,School of Applied and Creative Computing,png Information Type: pngSize: 219KBUploaded: Sep 16MD5: 38996968c22dbe4f8e07f460d98c9ef6Original Name: Shu Hu.png view move to AWS,https://web.ics.purdue.edu/~hu968/,Improving Fairness in Detecting AI-Synthesized Fake Multimedia,Improving Fairness in Detecting AI-Synthesized Fake Multimedia,,Applied Computer Science; Artificial Intelligence and Intelligent Systems; Computer Science; Media and communications; Other Computer and Information Sciences; Other Engineering and Technologies; Performance Evaluation and Benchmarking; Visualization and Human-Computer Systems,"DeepFake, a term increasingly mentioned in the news and social media, refers to highly realistic fake images, and videos created using AI algorithms. Combating DeepFake technology requires a comprehensive strategy that extends well beyond the realm of mere detection, emphasizing the responsible design, development, and deployment of technologies. This also known as responsible forensics, focuses on applying forensic science to digital content ethically, ensuring that actions to identify and mitigate DeepFakes meet high ethical standards and respect for human rights. At the heart of responsible forensics lies the commitment to fairness, especially important in the context of generative AI. It is crucial for detection tools to be crafted and used in ways that prevent unintentional bias against certain individuals or groups, thus upholding justice and equality in the digital realm. Therefore, our goal is to improve fairness in detecting novel DeepFakes.",Python Programming Skill.,,Improving Fairness in Detecting AI-Synthesized Fake Multimedia,DeepFake Detection; Media Forensics; Generalization; AI-generated Media,"Dr. Shu Hu is an assistant professor in the School of Applied and Creative Computing and the Director of the Purdue Machine Learning and Media Forensics (M2) Lab at Purdue University. He was a Post-Doctoral Fellow at the Heinz College of Carnegie Mellon University from 2022 to 2023. He received my Ph.D. degree in Computer Science and Engineering from the University at Buffalo, SUNY in 2022. He is the recipient of the National AI Research Resource (NAIRR) Pilot award (2024), the National Science Foundation CRII Award (2024), the Machine Intelligence Research Outstanding Reviewer Award (2023), and SUNY Buffalo's CSE Best PhD Dissertation Award (2022). His research interests include machine learning, media forensics, and computer vision."
proj104s1,Accept Wave 2 (Confirmed),Armstrong,Aboah,armstrong.aboah@ndsu.edu,North Dakota State University,,,,PRIME: A Foundational Predictive Real-time Intersection Monitoring Engine,PRIME: A Foundational Predictive Real-time Intersection Monitoring Engine,,Applied Computer Science; Artificial Intelligence and Intelligent Systems; Civil Engineering; Computer Science,"Traffic intersections remain critical points of vulnerability in transportation infrastructure, accounting for 20% of vehicular accidents and over 7,000 annual fatalities in the United States. Current intersection monitoring systems, relying on basic motion detection or single-class object detection, struggle with complex scenarios involving multiple road users and varying environmental conditions. This research proposes PRIME (Predictive Real-time Intersection Monitoring Engine), a foundational traffic intersection monitoring algorithm that integrates advanced deep learning techniques for multi-class video object detection and trajectory prediction. This project directly aligns with NAIRR priority areas by creating open-source foundation models for specific applications and utilizing experimental data from sensors and detectors. The proposed system employs a novel object detection architecture with enhanced feature pyramid networks and combines transformer encoders with graph neural networks to achieve robust object detection and accurate 5-second trajectory predictions. Our technical objectives include developing a multi-class detection system with over 95% accuracy, implementing proactive trajectory prediction, and generating anonymous traffic patterns for urban planning. The project will be executed utilizing TACC Frontera GPU resources for model development and training. We will also release our codebase and make our annotated dataset publicly available with the aim of establishing a common foundation for intersection monitoring systems.","A good programming background, like Python. Familiarity with computer vision.",,Towards a safe and smart intersection,"Machine learning, Safety, Intersection, trajectory","I am an Assistant Professor at the North Dakota State University. An ingenious and resourceful Transportation Data Scientist with a proven track record of success in research and hands-on experience developing cutting-edge database solutions, statistical modeling, data products, and computer vision systems aimed at improving transportation system management and operations. Has worked as an architect and application developer on a variety of projects that required the use of data mining and machine learning models to solve large-scale, complex, and difficult transportation problems. I am broadly interested in computer vision and machine learning. My research involves visual reasoning, vision and language, image generation, air taxis, naturalistic studies, and autonomous vehicles."
proj105s1,Accept Wave 2 (Confirmed),Yupeng,Zhang,yupeng@alumni.caltech.edu,"University of California, Los Angeles",,jpg Information Type: jpgSize: 85KBUploaded: Sep 16MD5: 8ff1a162ebcfed07230b96d9a1422d2bOriginal Name: self_2024.jpg view move to AWS,https://orcid.org/0000-0001-7149-451X,Iterative learning for materials and structures,Geometry Effects on Iterative Learning for Multiscale Modeling of History-Dependent Metamaterials,,"Applied Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent Systems; Civil Engineering; Computer Science; Geology and Solid Earth Sciences; Informatics, Analytics and Information Science; Infrastructure and Instrumentation; Materials Engineering; Mechanical Engineering; Other Computer and Information Sciences; Other Engineering and Technologies; Statistics and Probability; Visualization and Human-Computer Systems","A big challenge in advancing AI methods that enable scientific discovery is to understand what kinds of data are necessary to obtain accurate and transferable surrogate models. We explored this question in the context of the history-dependent behavior of materials and structures. We introduced an iterative approach where we used a rich arbitrary class of trajectories to train an initial model. We then iteratively updated the class of trajectories with those that arise in large-scale simulation and used transfer learning to update the model. We showed that such an approach converges to a highly accurate surrogate, and one that is transferable. In our current NAIRR Pilot project, we are investigating how geometry influences iterative learning in multiscale modeling of history-dependent metamaterials. Through the Sustainable Research Pathways (SRP) Program, we aim to develop AI/ML-based digital twins of physical materials and structures under various boundary conditions. The digital twins will serve as fast and reliable surrogates for multiscale modeling, optimization, and inverse design. This research connects AI/ML with mechanics, materials, structures, and design. Participants will gain experience with machine learning, numerical simulation, with applications spanning mechanical civil, and materials engineering.","Participants with interests in artificial intelligence, machine learning, numerical modeling, or materials / structures / mechanics are encouraged to apply. A background in engineering, computer science, applied math, applied statistics, or related fields is helpful, but not required. Curiosity and enthusiasm are especially valuable.",,AI/ML model for complex mechanical systems,"solid mechanics, materials characterization, Bayesian statistics, inverse problems, AI/ML, multiscale modeling of complex system, thermo-magneto-mechanical couplings.","Yupeng Zhang is currently with the Department of Mechanical and Aerospace Engineering at the University of California, Los Angeles (UCLA). He received his Ph.D. in Materials Science and Engineering from Texas A&M University, specializing in solid mechanics, Bayesian statics, and materials characterization, followed by postdoctoral positions at Northwestern University, and the California Institute of Technology. Zhang is a member of the ASCE - EMI Machine Learning in Mechanics Committee and the recipient of NAIRR grant as a single PI, the Future Faculty Symposium Travel Award from the Society of Engineering Science in 2023, the Clearfield Materials Fellowship at Texas A&M University, and the Mitacs Globalink Research internship from Mitacs Canada. Zhang has mentored over ten graduate and undergraduate students and serves as a reviewer for such as Journal of Applied Mechanics (ASME), Journal of Engineering Mechanics (ASCE), Mechanics of Materials (Elsevier), European Journal of Mechanics / A Solids (Elsevier), Journal of Materials Research (Springer), Journal of Engineering Materials and Technology (ASME), Experimental Mechanics (Society for Experimental Mechanics, SEM), Physics of Fluids(AIP). His research interests include solid mechanics, materials characterization Bayesian statistics, inverse problems, and AI/machine learning, focusing on multiscale modeling of complex system, and thermo-magneto-mechanical couplings."
proj106s1,Accept Wave 2 (Confirmed),Zhuangdi,Zhu,zzhu24@gmu.edu,George Mason University,,,http://zhuangdizhu.github.io/,Developing Engaging AI Chatbots to Enhance Senior Well-being,Developing Engaging AI Chatbots to Enhance Senior Well-being,,Applied Computer Science; Artificial Intelligence and Intelligent Systems; Health Sciences,"The mental well-being of the elderly population is a growing concern. According to the World Health Organization, approximately $14\%$ of adults aged 60 and over experience mental disorders, and the issues are often compounded by loneliness and social isolation. Large Language Models (LLMs) offer a promising solution by enabling meaningful, multi-turn dialogues. Leveraging the advanced natural language processing utility of LLMs, we aim to develop an AI chatbot specifically designed for seniors. Our research goal is to create an LLM-empowered dialog system that ensures engaging conversations for senior participants, thus supporting their cognitive functions and offering accessible interaction tools alongside traditional human interviews. It also underpins research for crucial applications such as detecting Mild Cognitive Impairment and intervening in the early stages of dementia.",Successfully led at least one project in a relevant domain or involving large language models (LLMs). + First-author experience in submitting research papers to leading ML/AI conferences. + Strong background in LLM-focused research programming and prompt engineering.,,Developing AI Chatbots for Improving Cognitive Health,Agentic AI Chatbot Cognitive Health User Study,"Zhuangdi Zhu is an assistant professor at the Department of Cyber Security Engineering of George Mason University. Prior to that, she worked as a senior Data & Applied Scientist for Microsoft. I received my Ph.D. degree from the Department of Computer Science and Engineering at Michigan State University. Her research centers around Accountable AI, through efforts in two directions: (1) advancing interactive AI to learn and reason over long horizons through principled Reinforcement Learning, and (2) decentralizing AI to the edge while balancing security, privacy, and efficiency."
proj107s1,Accept Wave 2 (Confirmed),Naeemul,Hassan,nhassan@umd.edu,University of Maryland,College of Information,,,AI for Quality Healthcare Information,Advancing Explainable LLM to Bridge the Knowledge-Practice Gap in Healthcare Communication,,"Applied Computer Science; Artificial Intelligence and Intelligent Systems; Computer Science; Health Sciences; Informatics, Analytics and Information Science; Media and communications; Other Computer and Information Sciences; Other Medical Sciences; Statistics and Probability; Visualization and Human-Computer Systems","This project investigates how large language models (LLMs) can help bridge the gap between scientific best practices and healthcare journalism. Research shows that news coverage of medical treatments often omits critical details such as harms, evidence quality, or alternatives leading to public misunderstanding and even harmful health decisions. While frameworks exist to assess the quality of healthcare news, they are labor-intensive and not scalable. Our project explores the potential of LLMs (e.g., GPT models, LLaMA) to automatically evaluate healthcare news articles against science-informed criteria, provide explainable feedback, and support journalists in improving reporting quality. We will test models on a curated dataset of 2,000 expert-annotated healthcare articles and extend the evaluation to larger datasets.","The project blends computational journalism, natural language processing, and human-computer interaction to advance both AI explainability and its practical applications in healthcare communication. Relevant expertise- Interest in AI/LLMs, computational journalism, or healthcare communication Familiarity with Python, machine learning, or NLP libraries (e.g., Hugging Face, OpenAI API) Experience with data annotation, text analysis, or evaluation frameworks Curiosity about interdisciplinary research that combines computer science, journalism, and public health Strong analytical and communication skills, with an openness to learning across fields",,Advancing Explainable LLM to Bridge the Knowledge-Practice Gap in Healthcare,Artificial Intelligence; Large Language Model; Health Information; Natural Language Processing,"Dr. Naeemul Hassan is an Associate Professor in the Philip Merrill College of Journalism at the University of Maryland, jointly appointed with the College of Information Studies (iSchool). His research lies at the intersection of computational journalism, data science, and artificial intelligence, focusing on combating misinformation and enhancing the transparency and efficiency of news production. Dr. Hassan’s work combines natural language processing, machine learning, and human-centered approaches to improve how information is produced, verified, and consumed."
proj109s1,Accept Wave 2 (Confirmed),Xiao,Wang,xiaowangatpurdue@gmail.com,Oak Ridge National Laboratory,,jpg Information Type: jpgSize: 756KBUploaded: Sep 17MD5: 3e4ead91c3b1185356294792f54a5deeOriginal Name: IMG_0151.JPG view move to AWS,https://www.ornl.gov/staff-profile/xiao-wang,Computing-Efficient Training for Large-Scale Vision Transformer Foundation Models,Computing-Efficient Training for Large-Scale Vision Transformer Foundation Models,,Applied Computer Science; Artificial Intelligence and Intelligent Systems; Computer Science,"Vision Transformer (ViT) is a powerful AI architecture for computer vision that is used by most imaging foundation models due to its effectiveness in discerning complex visual patterns across many tasks. However, training large-scale ViT foundation models requires considerable computing resources, leading to a significant energy footprint for training. For example, Open-AI’s SORA video generator model was trained on more than 10,000 NVIDIA H-100 GPUs and the training took more than a month on a supercomputer. The energy consumption for training SORA was equivalent to the total annual energy consumption of 300 US households. This one-year project aims to improve ViT scaling algorithms computing efficiency, reducing AI development cycle and training time. We will develop a training framework optimized for hardware-conscious scaling and computing efficiency, specifically tailored for large-scale ViT models.","AI, efficient computing",,Energy Efficient Vision Transformer Training Framework For Exascale Foundation Models,"vision transformer, exascale foundation model, high performance computing, energy efficiency","Dr. Xiao Wang is a research staff scientist in the Computational Science and Engineering Division at Oak Ridge National Laboratory (ORNL). He earned dual Bachelor's degrees in Mathematics and Computer Science from Saint John’s University, MN (2012), and completed his M.S. and Ph.D. in Electrical and Computer Engineering at Purdue University (2016–2017) under Dr. Charles Bouman and Dr. Samuel Midkiff. Before joining ORNL in 2021, he conducted postdoctoral research at Harvard Medical School and Boston Children’s Hospital, focusing on medical imaging. Dr. Wang’s research lies at the intersection of artificial intelligence (AI), high-performance computing (HPC), and computational imaging. He develops algorithms that integrate AI, imaging physics, and HPC to enable high-resolution, data-efficient imaging across modalities such as X-ray, CT, MRI, electron tomography, and satellite imaging, with applications in medicine, biology, climate science, and national security. He received the 2022 AAPM Truth CT Reconstruction Challenge award, was a finalist for the ACM Gordon Bell Prize in 2017 and 2024, and received the 2024 HPCWire Top Supercomputing Achievement Award. His current work focuses on scalable, energy-efficient, and trustworthy Vision Transformer foundation models for large-scale imaging applications."
proj113s1,Accept Wave 2 (Confirmed),Yang,Liu,y-liu@tamu.edu,Texas A&M University,Department of Nuclear Engineering,,,LLM-Enhanced Cyber-Physical Testbed for Advanced Reactor Monitoring and Predictive Maintenance,LLM-Enhanced Cyber-Physical Testbed for Advanced Reactor Monitoring and Predictive Maintenance,,Artificial Intelligence and Intelligent Systems; Mechanical Engineering; Other Engineering and Technologies,"This project aims to harness cutting-edge large language models (LLMs) to enhance real-time monitoring, anomaly detection, and predictive maintenance in a thermal-fluid facility designed for advanced nuclear reactors. By integrating sensor data, experimental logs, and domain-specific knowledge, the LLM-based platform will identify off-normal events and potential cybersecurity threats, providing timely diagnostics to operators. The resulting methods and tools will be published openly, enabling broader adoption within the nuclear industry and fostering safer, more efficient reactor operations.","Generative AI, Large language model, Retrieval-Augmented-Generation, AI Agents, Context engineering.",,Domain Knowledge-Enhanced Generative AI for Advanced Energy Research and Development,Generative AI; Advanced Energy Systems; Automating Engineering Workflow; Real-Time Remote Monitoring and Control; Modeling and Simulation; Retrieval Augmented Generation,"Dr. Yang Liu is an Assistant Professor of Nuclear Engineering at Texas A&M University. He leads the Scientific Machine learning for Advanced Reactor Technologies (SMART) lab and serves as the director of the Generative AI for Science and Engineering (GAISE) Lab under Texas A&M Institute of Data Science. Prior to joining TAMU, he held positions as staff at Argonne and postdoc at University of Michigan. His research focuses on the intersection between AI/ML and advanced energy systems, including (a). Physics-informed machine learning; (b). Digital twin-enhanced experimentation; and (c). Generative AI for science and engineering. Dr. Liu has published more than 50 papers in refereed journals and conference proceedings. He is a recipient of US. Department of Energy Nuclear Energy Office's Distinguished Early Career Award in 2024."
proj115s1,Accept Wave 2 (Unconfirmed),Dongyeop,Kang,dongyeop@umn.edu,University of Minnesota,Computer Science & Engineering,jpg Information Type: jpgSize: 59KBUploaded: Sep 22MD5: fca0d074642e2d9c3dd2e6caa0b9f275Original Name: dykang2.jpg view move to AWS,https://dykang.github.io/,Building Trustworthy Scientific Foundational Model,Scientific Foundational Model Development for Supporting Trustworthy Scholarly Writing,,Artificial Intelligence and Intelligent Systems,"Scholarly writing is a complex cognitive task requiring continuous decision-making, extensive working memory, and multitasking. Developing effective scholarly writing assistants is challenging due to the issue of non-factual responses from large language models (LLMs) and isolated assistance at different stages of writing. Our project aims to develop scientific foundational models that provide reliable, multimodal support for the entire writing process, including text, images, code, social media discussions, and peer reviews. We will enhance trust by marking original reference sources in generated content and linking references across modalities. Upon completion, we will release two open-source models: a pretrained LLM identifying reference sources in outputs, and a fine-tuned VLM for vision-language tasks. All data, model weights, and training details will be openly shared to promote scientific transparency. These models are expected to enhance scientific discovery and contribute to the development of reliable, safe AI across various fields.","Ideal participants should have skills in machine learning and NLP, including experience with large language models (LLMs), and Python-based development. They should understand scholarly writing processes, reference management, and data curation for text, images, and code. Strong interests in open science, and creating trustworthy systems are essential. Collaborative abilities, clear communication, and a willingness to learn and mentor are also important.",,,,
proj117s1,Accept Wave 2 (Confirmed),Anima,Anandkumar,anima@caltech.edu,Caltech,Computing and Mathematical Sciences,,https://tensorlab.cms.caltech.edu/,Neural Operators for Scalable and Sustainable Scientific Modeling,Aligning AI models for scientific simulations under a physics-informed framework,,Applied Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent Systems; Computer Science; Other Computer and Information Sciences,"Addressing global sustainability challenges requires fast, accurate, and generalizable modeling of complex systems in energy, climate, and infrastructure. Traditional high-fidelity simulations are often too slow and computationally expensive for timely exploration, design, and decision-making. This project leverages and advances neural operator frameworks to accelerate scientific simulations while adhering to known physical laws. By combining the expressiveness and inference speed of deep learning architectures with physics knowledge, these neural operators provide predictive surrogates for systems governed by partial differential equations, enabling scalable, energy-efficient computation at previously inaccessible scales. In this research, embedding physical constraints ensure sreliable predictions, generalizes modeling across diverse domains, and enables inverse design to identify system configurations that meet performance goals. Uncertainty quantification and formal verification in Lean (a theorem prover) provide further guarantees of correctness and reliability. Physics-informed enhancements, operator-based multi-scale learning, and robust modeling strategies ensure accurate long-term behavior and broad applicability to complex real-world systems. These tools support high-impact simulations for renewable energy, environmental resilience, and critical infrastructure planning. By releasing open-source frameworks, fostering accessibility, and prioritizing usability, this work empowers scientists, engineers, and students worldwide to harness advanced neural operators for transformative discovery, informed decision-making, and sustainable, verifiable solutions to urgent global challenges.","- Knowledge of machine learning fundamentals - Strong programming skills and experience with scientific computing and deep learning libraries (e.g., Python, PyTorch) - Familiarity with differential equations and numerical methods - Interest in computational modeling and applying AI to scientific problems - Enthusiastic and proactive in exploring new research questions, methods, and learning opportunities - Open-minded and adaptable, eager to engage with diverse scientific approaches and perspectives - Passion for interdisciplinary research bridging AI and physical sciences - Effective communication skills - (Optional) Familiarity with theorem provers such as Lean or an interest in learning them can be helpful for certain specific directions, though not required for most directions",,Neural Operators for Scalable and Sustainable Scientific Modeling,AI for science; neural operators; physics-informed ML; accelerating simulations and scientific discovery; inverse design;,"Anima has made fundamental contributions to AI that is revolutionizing scientific modeling and discovery. She invented Neural Operators for learning multiscale phenomena that frequently occur in nature, such as fluid dynamics, material modeling and wave propagation. She employed Neural Operators to train the first AI-based high-resolution weather model, tens of thousands of times faster than existing physics-based forecasting. Her AI algorithms have enabled many other scientific advances such as modeling plasma evolution in nuclear fusion, enabling safer autonomous drone flights, and designing novel medical devices, drugs, and functional enzymes. Earlier in her career, Anima spearheaded the development of tensor methods, probabilistic latent variable models, and analysis of non-convex optimization. Anima is Bren Professor at Caltech. She previously was a Senior Director of AI Research at NVIDIA and Principal Scientist at Amazon Web Services. She received her B.Tech from IIT Madras, and her Ph.D. from Cornell University. She did her postdoctoral research at MIT and an assistant professorship at UC Irvine. She has received several honors such as the IEEE fellowship, Alfred. P. Sloan Fellowship, NSF Career Award, and Faculty Fellowships from Microsoft, Google, Facebook, and Adobe. She is part of the World Economic Forum's Expert Network."
proj119s1,Accept (Confirmed),Megan,Phinney,mphinney@lanl.gov,Los Alamos National Laboratory (LANL),,,,Super Containers at Super Scale,,Charliecloud,High Performance Computing,"Your job will be software development on Charliecloud: programming; writing and editing documentation; and analyzing bug reports and feature requests. You will participate in the broader project, such as internal/external collaborations, strategy planning, code review, and research. You will collaborate with colleagues inside and outside LANL, both formally and informally, in both written and oral contexts. Finally, you will participate in technical events (e.g., lectures) and professional development activities across LANL. This is a mentored role, and your success will be a top priority for your mentor. Expect to see them on a daily basis for detailed technical and professional guidance and be fully on-site to facilitate better collaboration in this junior role.","An understanding how the command line works, Linux/Unix, Shell commands, Git, Python, C, and POSIX sh programming",,Super Charliecloud Containers at Super Scale,Containers; Linux/Unix Shell commands; Git; Python; C; POSIX sh programming,"Megan earned a B.S. in computer engineering at Iowa State University in 2022. She joined Los Alamos National Laboratory in 2020 as an undergrad student and was promoted to staff scientist in 2022. At LANL, she works on container runtimes and workflows as a part of the Charliecloud project. She also provides user support for HPC systems. In her free time, she enjoys reading, hiking, and playing with her pit bull."
proj120s1,Accept Wave 2 (Unconfirmed),Dalton,Lunga,lungadd@ornl.gov,Oak Ridge National Laboratory,Geospatial Science and Human Security,,,Geospatial AI Foundation Models,Georeferenced Multimodal Foundation Models for Earth Sciences,,Artificial Intelligence and Intelligent Systems; Computer Science; High Performance Computing; Other Earth and Environmental Sciences; Performance Evaluation and Benchmarking,"This project seeks to prototype a proof-of-concept next generation geospatial foundation model that integrate geospatial knowledge, physical processes, temporal dynamics, and human actions to support pressing energy, security, and environmental challenges. We will take inspiration from the NVIDIA Cosmos – a platform for training general purpose world foundation models for physical AI and seek to prototype world models to support GeoAI foundation models that are equipped with capturing dynamic states of the physical world.","Artificial Intelligence, Generative AI (Diffusion Models), Image and Video Processing, Remote Sensing, High Performance Computing, Image and Video Synthesis, Self Supervised Learning, Graph Neural Networks",none,,,
proj123s1,Accept Wave 2 (Confirmed),Edgar,Lobaton,edgar.lobaton@ncsu.edu,North Carolina State University,,,,AI-Guided Learning in JupyterHub Environments,Providing GPU Resources for Deep Learning at NC State,,"Applied Computer Science; Educational Sciences; Electrical, Electronic, and Information Engineering","Ready to build the future of coding education? This high-impact research project invites motivated students to integrate Large Language Models (LLMs) into the JupyterHub platform for technical coursework, with the core goal of transforming the LLM from a passive tutor into an active, reflective guide. You'll be responsible for developing and deploying the LLM interface within Jupyter Notebooks, implementing a fine-grained tracking and logging mechanism to capture student-LLM interaction data, and creating prompt engineering strategies that strictly enforce the LLM's role as a ""navigator"", while offering directional guidance, samples and logic critiques rather than direct solutions. This work lies at the critical intersection of AI, Human-Computer Interaction, and Educational Technology, offering a unique opportunity to directly influence how the next generation of technical professionals learns to code by leveraging AI as a powerful learning partner.","- Proficiency in Python programming - Familiarity with the use of the API for any LLM (e.g., OpenAI API) - [Desired but not required] Familiarity with Kubernetes","As part of this project, you will also help with expanding on the features of our existing JupyterHub infrastructure through JetStream2.","LLMs as Co-Pilots in Scientific Modeling, Coding and Learning",Code assistant; LLMs; AI as a guide; Physics Modeling,"Edgar J. Lobaton is a Professor in the Department of Electrical and Computer Engineering (ECE) at North Carolina State University (NCSU). He joined the department in 2011. Lobaton earned his B.S. in Mathematics and Electrical engineering from Seattle University in 2004. He completed his Ph.D. in Electrical Engineering and Computer Sciences from the University of California, Berkeley in 2009. Lobaton was engaged in research at Alcatel-Lucent Bell Labs in 2005 and 2009. He was awarded the NSF CAREER Award in 2016. He was also awarded the 2009 Computer Innovation Fellows post-doctoral fellowship and conducted research in the Department of Computer Science at the University of North Carolina (UNC) at Chapel Hill from 2009 until 2011. In 2023, he received the William F. Lane Outstanding Teaching from the ECE Department. In 2024, he received the University Faculty Scholars and the Outstanding Teacher Awards from NC State. His research focuses on the integration of AI, and physical and probabilistic modeling applied to cyber-physical systems in areas such as wearable health monitoring, rehabilitation robotics, agriculture and biological imaging."
proj125s1,Accept (Confirmed),Kenneth,Moreland,morelandkd@ornl.gov,Oak Ridge National Laboratory (ORNL),,,https://www.kennethmoreland.com/,Advanced Scientific Visualization with Viskores,,Viskores,Computer Science; High Performance Computing; Open Source Software; Software Engineering; Visualization and Human-Computer Systems,"This project involves the Viskores software library (https://github.com/Viskores/viskores). This library provides functionality to process data that, most often, is generated by physics simulations and provides visual representations to improve data understanding. The Viskores algorithm performs numerous types of computational geometry to extract visually meaning features from data such as contour surfaces from fields and tracing paths within flow. Viskores is also responsible for the rendering of such features using a variety of computer graphics techniques. The specifics of the project will be tailored to the intern’s interests and abilities. The primary needs of the project involve an expansion of Viskores rendering capabilities, optimization of Viskores algorithms, and improved Viskores documentation.","C++; Familiarity with entering commands in a command prompt (e.g, terminal, xterm, powershell, etc.)",,Visualization at Exascale with Viskores,visualization; HPC; GPU,"Dr. Kenneth Moreland is a senior research scientist at Oak Ridge National Laboratory. He received BS degrees in computer science and in electrical engineering from the New Mexico Institute of Mining and Technology in 1997. He received MS and Ph.D. degrees in computer science from the University of New Mexico in 2000 and 2004, respectively. Dr. Moreland specializes in large-scale visualization and graphics and plays an active role in the development of several HPC products including Viskores, ParaView, VTK, IceT, and Catalyst. His current interests include the design and development of visualization algorithms and systems to run on multi-core, many-core, and future-generation computer hardware."
proj126s1,Accept (Confirmed),Damien,Lebrun-Grandie,lebrungrandt@ornl.gov,ORNL,,,https://www.ornl.gov/staff-profile/damien-lebrun-grandie,Kokkos Tools,,Kokkos,Applied Computer Science; High Performance Computing; Performance Evaluation and Benchmarking; Software Engineering,"This internship focuses on developing Kokkos Tools, a vital suite of libraries for analyzing and optimizing Kokkos applications without changing the source code. You will help expand the Kokkos Tools ecosystem by building: Performance & Energy Profiling tools to measure execution time, memory usage, and energy consumption. This work helps developers identify bottlenecks and optimize code for diverse hardware, including CPUs and GPUs. Code Sanity & Debugging tools to detect and diagnose common programming errors and invalid usage of the Kokkos API, ensuring code correctness. You will contribute to a major open-source project used globally in High-Performance Computing (HPC). You'll gain hands-on experience in parallel programming, performance-portability, and the full software development lifecycle. This is a chance to build critical skills in performance analysis and debugging while connecting with the international HPC community.","We're looking for candidates with a passion for High-Performance Computing (HPC) and parallel programming. Relevant backgrounds could include Computer Science, Engineering, or a related technical field. Ideal interests and skills include: Experience with C++ (or a similar high-performance language). Familiarity with parallel programming models (e.g., CUDA, OpenMP, MPI, or Kokkos). An interest in performance analysis and finding ways to optimize code. A desire to contribute to a large-scale open-source project.",,Your Summer Project: Taming the World's Fastest GPUs,Performance Portability; Exascale Computing; C++; Heterogeneous Architectures; GPU; Parallel Programming; Tooling / Profiling,"Damien Lebrun-Grandié is a Senior Computational Scientist at Oak Ridge National Laboratory with over a decade of experience in the field. He holds a PhD in Nuclear Engineering from Texas A&M University, a MSc in Physics from the Karlsruhe Institute of Technology in Germany, and a MEng in Physics Engineering from Grenoble INP in France. His research focuses on developing algorithms and enabling technologies for solving large-scale, complex engineering, and scientific problems. As a founding member of the High Performance Software Foundation, Damien was instrumental in getting the organization started and continues to play a leading role on the Governing Board, representing the Technical Advisory Council. He is also the co-lead of the Kokkos C++ performance portability project, where he oversees a large international team of developers and researchers. Additionally, he represents ORNL on the C++ Standards Committee, where he has been a key contributor to foundational features for scientific computing like std::mdspan in C++23 and std::linalg for C++26."
proj128s1,Accept (Confirmed),Todd,Gamblin,tgamblin@llnl.gov,LLNL,Livermore Computing,jpg Information Type: jpgSize: 196KBUploaded: Oct 03MD5: 0e975e2d14afbe32e881a7785ba0a61cOriginal Name: me-greatwall-fron... view move to AWS,,Spack at LLNL,,Spack,Applied Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent Systems; Computer Science; High Performance Computing; Open Source Software; Software Engineering,"Depending on experience and interest, we will develop a project dealing with the open source Spack package manager (https://github.com/spack/spack) or the Spack package ecosystem (https://github.com/spack/spack-packages). Spack has become the de-facto package management tool for High Performance Computing, an area where software complexity is constantly rising. Spack helps users build, install, and manage software on laptops, desktops, and supercomputers. With over 1,500 contributors and over 8,500 package recipes, Spak provides a valuable resource for HPC users around the world. Example projects would include new core features for Spack, including terminal UI improvements, performance improvements, or enhancements to Spack's solver or other capabilities. Projects could also focus on package recipe improvements, e.g. improvements to AI packages or GPU support, improvements to Spack's continuous integration system. We can tailor the project to the applicant's experience and interest. On this project, you’ll learn more about the core of Spack, how it builds software, and how large software ecosystems are sustained through community effort.","For core Spack projects, we expect experience with Python and some Linux systems programming. An ideal candidate will have at least some experience with building and installing software, especially with build systems like CMake and Autotools. Low-level systems experience, e.g. UNIX process control, file I/O, and performance profiling are a plus. Experience with performance optimization and with using package managers, Spack or otherwise, are a plus.",,,,
proj129s1,Accept (Confirmed),Andrew,`Myers,atmyers@lbl.gov,LBNL,Applied Mathematics,,https://profiles.lbl.gov/22224-andrew-myers,Python-driven workflows with AMReX,,AMReX,Applied Computer Science; Applied Mathematics; High Performance Computing; Software Engineering,"AMReX is a publicly available software framework designed for building massively parallel block- structured adaptive mesh refinement (AMR) applications. Simulation codes based on AMReX model a wide range phenomena from fields ranging from astrophysics and cosmology to plasma physics, earth systems modeling, multi-phase flow, epidemiology, cell biology, and more. While AMReX is written in C++, for this internship we are envisioning several projects that involve improving and expanding the Python interfaces to AMReX with the goal of supporting new AI/ML use cases, including: 1. Integrating simulations with ML-based Bayesian optimization workflows 2. Training fast surrogate models and incorporating those into simulations 3. Automatic differentiation of coupled C++ simulation and Python analysis code through tools like Enzyme. 4. Uncertainty quantification using frameworks like PyTUQ. The above workflows will be demonstrated on and evaluated with real-world AMReX-based application codes.","Experience with Python is desired, other useful skills include experience with C++, AI/ML, and high-performance computing.",,AMReX: Adaptive Mesh Refinement for Exascale,Adaptive Mesh Refinement; Math libraries; Scientific Computing; C++; Python; AI/ML; automatic differentiation; uncertainty quantification,"Andrew joined Berkeley Lab in 2013 as a postdoctoral researcher in the Applied Numerical Algorithms Group. He is now a staff member in the Center for Computational Sciences and Engineering, where he designs and implements HPC algorithms for solving multiscale, multiphysics problems using structured adaptive meshes and particles. He is a core contributor to the AMReX adaptive mesh library, and also contributes to a number of AMReX-based simulation codes in subjects ranging from computational plasma physics to epidemiology. He was a member of the 2022 Gordon-Bell prize-winning team for kinetic plasma simulations with the WarpX Particle-in-Cell code, and received a Director's Award for Exceptional Scientific Achievement in 2023."
proj133s1,Accept Wave 2 (Unconfirmed),zhou,yu,zy2461@columbia.edu,Columbia University,,png Information Type: pngSize: 210KBUploaded: Oct 07MD5: 572820134149095d5f9e324d01bf9c2cOriginal Name: 007.png view move to AWS,,"Enhancing Privacy-Preserving LLM Pipelines: Expanding Benchmarks, Improving Local Model Performance, and Exploring Complex System Structures","Enhancing Privacy-Preserving LLM Pipelines: Expanding Benchmarks, Improving Local Model Performance, and Exploring Complex System Structures",,Artificial Intelligence and Intelligent Systems; Computer Science,"This project investigates privacy-preserving methods for Large Language Model (LLM) applications, focusing on preventing the disclosure of Personally Identifiable Information (PII) to untrusted LLMs at inference time. Building upon the previously developed PAPILLON pipeline, which leverages trusted but weaker local models to selectively utilize untrusted but powerful API-based models, this research aims to enhance the pipeline's capabilities and address limitations. The project will involve expanding the existing PUPA benchmark dataset with synthetic data and additional real-world conversations, improving the performance of smaller local LLMs through techniques like Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO), and exploring more complex system structures for handling intricate user requests. Additionally, a user study will be conducted to investigate the discrepancies between human and LLM understandings of PII, contributing to better alignment between user expectations and model behavior",NLP and ML experience. Python coding experience,,,,
proj134s1,Accept Wave 2 (Confirmed),Varun,Kasireddy,vkasired@alumni.cmu.edu,Carnegie Mellon University,Robotics,,https://teamchiron.ai,Visual Language Model for Stand-off Triage Sensing,LLM Training and Evaluation for Pandemic Prevention and Response,,Computer Science,"We build vision-language systems that help robots perform fast, reliable casualty triage. As our work involves practical edge deployment (e.g., NVIDIA Jetson), a critical aspect in our decision making is to balance algorithm accuracy with latency requirements. By Summer 2026, the project will be at a point where students will test and iterate on existing pipelines—video highlight extraction, robust person and blood segmentation, and Visual Question Answering (VQA) for scene understanding. Each week, we will run systems tests and score performance. Based on the results, students should quickly synthesize progress, create short presentations for the broader team, and help the project leads finetune models and manage versioning to push improvements for the next deployment. Work spans dataset preparation, annotation, benchmarking, and optimization on GPU clusters. The aim is clear tools that fit robotic workflows. Impact includes emergency response, safety monitoring, and human-robot teaming. It’s hands-on and fast-paced—you’ll see changes week to week and get to validate them on real hardware.","• Core: Python, basic Linux, Docker containerization, and comfort with Git/GitHub for fast iteration. • Robotics: ROS 2 basics (nodes, topics, launch files) to run weekly systems tests and integrate updated components. • Experiment tracking: Weights & Biases (W&B) for logging metrics, comparing runs, and sharing dashboards with the team. • Evaluation: Clear thinking about test scores, precision/recall, latency, and failure cases; ability to propose quick fixes. • Data pipelines: PyTorch, computer vision, segmentation, dataset curation/annotation (e.g., CVAT/FiftyOne), and simple GPU optimization. • Optional: Edge deployment (e.g., NVIDIA Jetson)",,Push AI-driven robots to the field,Robotics; Multimodal Perception; Vision‑Language Models; Edge Computing; ROS 2; Real‑Time Evaluation; Reliable AI; Field Testing; Sensor Fusion; LiDAR,"Varun Kasireddy is a Project Scientist at Carnegie Mellon University’s AirLab. His research focuses on multimodal perception, vision–language models, and learning on edge devices. He also collaborates with academic and industry partners, including efforts on autonomous aerial systems for object identification and tracking. Varun is committed to reproducible research, practical evaluation, and human‑in‑the‑loop development. He mentors students on concise experimentation, observability, and data quality, and enjoys designing small-scale prototypes that translate quickly to field trials. Through SRP, he aims to build a collaborative summer project that combines rigorous evaluation with scalable perception to deliver reliable robotic behaviors in real environments."
proj136s1,Accept Wave 2 (Confirmed),Agniv,Sengupta,agsengupta@ucsd.edu,University of California San Diego,Scripps Institution of Oceanography,jpg Information Type: jpgSize: 3MBUploaded: Oct 08MD5: f66aa5f053cad335f8215df3d1ee49f6Original Name: Agniv_Sengupta_ph... view move to AWS,https://agsengupta.scrippsprofiles.ucsd.edu/,AI Models for the Prediction of Extreme Weather Events,Development of AI Data-driven Models and Very Large Ensembles for the Prediction of Atmospheric Rivers and Extreme Weather Events,,Artificial Intelligence and Intelligent Systems; Atmospheric Sciences,"Accurate weather forecasting has traditionally relied on numerical weather prediction models, which require significant computational resources. In this context, artificial intelligence (AI) models have revolutionized the domain of weather prediction in the past 2-3 years, emerging as computationally efficient alternatives. As part of our NAIRR Pilot project, we are developing such AI weather modeling and prediction capabilities over the North Pacific and the western United States, specifically for extreme weather phenomena such as atmospheric rivers (ARs). In this work, we utilize state-of-the-art AI advancements, including graph neural networks and Diffusion-based Generative AI methods. Additionally, we employ these models to generate a large number of realizations of future weather, enhancing the tracking of AR storms from their genesis over the Pacific to their impact over the U.S. West Coast.","Interest in AI/ML, Meteorology, or Climate Science Experience with, or a desire to learn: * Python * Statistics * Data Analysis * Data Visualization * Machine Learning tools (e.g., PyTorch, TensorFlow, Keras, Scikit-learn) Coursework or experience in Statistics or Data Science is preferred. Familiarity with Machine Learning is a plus.",Opportunity to be co-hosted alongside a cohort of interns selected through the Scripps Institution of Oceanography (SIO)/CW3E Summer Internship Program at the beautiful SIO campus overlooking the Pacific Ocean.,AI Data-driven Models for the Prediction of Extreme Weather Events,Weather; Meteorology; Artificial Intelligence; Machine Learning,"Dr. Agniv Sengupta is a Sr. Computational Research Scientist and the Machine Learning Team Lead of the Center for Western Weather and Water Extremes (CW3E), Scripps Institution of Oceanography at UC San Diego. His research interests involve the prediction of high-impact weather events using artificial intelligence and machine learning. His current projects focus on improving the prediction skill of weather (0-10 days), subseasonal (1-6 weeks), and seasonal (1 to 6 months) forecasts in the Western United States. This involves exploring innovative algorithms and approaches, advancing models for predictions across multiple timescales, and developing decision-support tools and forecast products in coordination with stakeholders. Dr. Sengupta earned his Ph.D. (2020) and M.S. (2016) in Atmospheric and Oceanic Science from the University of Maryland College Park, and was subsequently a postdoctoral scholar (2020-21) at the NASA Jet Propulsion Laboratory (JPL) prior to joining CW3E."
proj137s1,Accept Wave 2 (Confirmed),Reno,Kriz,rkriz1@jhu.edu,Johns Hopkins University,Human Language Technology Center of Excellence,jpg Information Type: jpgSize: 2MBUploaded: Oct 08MD5: e62d9f661ef32b6fba6ad6916823825eOriginal Name: reno_headshot.jpeg view move to AWS,https://hltcoe.jhu.edu/researcher/reno-kriz/,SCALE 2026: Event Understanding and Summarization from Real-time Videos,Advancing Scientific Discovery through Multilingual/Multimodal Summarization at SCALE 2025/2026,,"Artificial Intelligence and Intelligent Systems; Computer Science; Electrical, Electronic, and Information Engineering; Informatics, Analytics and Information Science","understand real-time, multilingual video content is increasingly important. From smartphone footage of natural disasters to public livestreams near high-risk infrastructure, these unedited clips offer firsthand evidence of unfolding events. Combined with audio and embedded text, they form a rich multimodal source that remains underutilized in current retrieval-augmented generation systems. Especially for real-time situations, scientific advances grounding articles in video can combat misinformation and help journalists quickly synthesize information from non-traditional, cross-lingual platforms. SCALE 2026, a 10-week workshop hosted by the Human Language Technology Center of Excellence (HLTCOE) at Johns Hopkins University, provides a realistic setting for advancing real-world multimodal understanding. During the summer, we will evaluate modality-specific technologies for extracting relevant signals from raw video data. First-stage research areas include audio and visual event detection, speech and audio summarization, and OCR or visual frame analysis. These signals will inform the second stage, our primary task of multimodal retrieval-augmented generation. Given an information need and a collection of raw multilingual videos, the system must retrieve relevant content and generate a coherent summary of the most significant information. Second-stage research areas include multimodal information retrieval and multi-video summarization.","We welcome participants with backgrounds or interests in natural language processing, computer vision, and multimodal technologies. Relevant experience might include work with large language or vision-language models, video or audio understanding, and multilingual or low-resource technologies. Participants interested in areas such as event detection, speech processing, optical character recognition, information retrieval, or summarization are especially encouraged to apply. SCALE projects are highly collaborative, bringing together researchers from diverse areas of expertise, so openness to interdisciplinary teamwork and shared problem-solving is essential.","SCALE (the Summer Camp for Applied Language Exploration) is an annual 10-week research program hosted by the HLTCOE at Johns Hopkins University since 2009. For more on its history and past topics, see https://hltcoe.jhu.edu/research/scale/. SCALE 2026 builds on the two most recent workshops: SCALE 2024, focused on event-centric video retrieval, and SCALE 2025, which explored retrieval-augmented generation for request-guided summarization of multilingual sources.",SCALE 2026: Event Understanding and Summarization from Real-time Videos,multimodal retrieval-augmented generation; multi-video summarization; video retrieval; speech/audio summarization; optical character recognition; audio/visual event detection; computer vision; speech processing,"Reno Kriz is a research scientist at the Johns Hopkins University Human Language Technology Center of Excellence (HLTCOE). His primary research interests involve leverage large pre-trained models for a variety of natural language understanding tasks, including those crossing into other modalities, e.g., vision and speech understanding. These multimodal interests have recently involved the 2024 and 2026 Summer Camps for Language Exploration (SCALE) on event-centric video retrieval, understanding, and summarization. He received his PhD from the University of Pennsylvania where he worked with Chris Callison-Burch and Marianna Apidianaki on text simplification and natural language generation. Prior to that, he received BA degrees in Computer Science, Mathematics, and Economics from Vassar College."
proj140s1,Accept Wave 2 (Confirmed),Shi Zhuo,Looi,looi@caltech.edu,California institute of technology,"Mathematics (Division of physics, mathematics and astronomy)",jpg Information Type: jpgSize: 114KBUploaded: Oct 09MD5: 38cdb0a0e0b33ef6becea12d2c884eb2Original Name: unnamed (1).jpg view move to AWS,https://sites.google.com/view/s-looi/,AI-Driven Methods for Discovering and Proving Mathematical Inequalities,AI-Driven Methods for Discovering and Proving Mathematical Inequalities,,Applied Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent Systems; Computer Science; High Performance Computing; Performance Evaluation and Benchmarking; Training,"Our proposed work advances AI for Accelerating Science and Discovery, a core focus area of the NAIRR Pilot, by developing a specialized, AI-driven framework for discovering and proving mathematical inequalities. Inequalities are foundational tools across scientific and engineering domains, from verifying stability in partial differential equations to bounding error terms in applied mathematics and physics. By combining large language models, reinforcement learning (RL), and symbolic computation, we aim to automate and accelerate the process of finding new results in both classical and cutting-edge mathematical research. This will facilitate the proof of inequalities and has the potential to enable new discoveries in science and engineering where precise mathematical bounds are important.",Experience training models and/or handling datasets for language models,,AI-Driven Discovery and Proof of Mathematical Inequalities,,"Looi works in mathematical analysis, evolutionary PDEs, and AI. A core part of his research in analysis and PDEs involves the study of inequalities, including functional and polynomial inequalities, which are intimately related to many areas of pure and applied mathematics. In the AI-math domain, his contributions include proving theorems on the controllability of self-attention in “What’s the Magic Word?”, leading the data team at Project Numina (winner of the 2024 AIMO Prize), and advancing Lean-4 formalization in PDEs. He is a founding scientific advisor to ScienceStack, a platform for interactive, machine-readable papers. His work aims to merge machine learning, formal methods, and math to build reliable and reproducible reasoning workflows in mathematics."
proj141s1,Accept Wave 2 (Confirmed),Zhe,Zhang,zhezhang@tamu.edu,Texas A&M University,Geography,jpg Information Type: jpgSize: 484KBUploaded: Oct 09MD5: 2b76038cf01c04c1ac1e9272dfa76666Original Name: zhesarina-zhang.jpg view move to AWS,,Utilizing NAIRR Pilot Resources for Building Sustainable Blue Economy,Utilizing NAIRR Pilot Resources for Building Sustainable Blue Economy,,Educational Sciences; Environmental Biology; Environmental Biotechnology; Environmental Engineering; Other Earth and Environmental Sciences,"The Gulf of America faces significant challenges for Blue Economy research, including environmental degradation from pollution and overfishing, as well as the impacts of natural disasters. These issues strain marine ecosystems and coastal communities, creating barriers to sustainability. Similarly, the mid-Atlantic region, such as Maryland, suffers from agriculture, urban runoff, and industrial activities that degrade water quality and significantly impact fish populations and the overall health of the fishery. Hawaii, meanwhile, encounters unique challenges due to its geographic isolation and heavy reliance on ocean resources. This project aims to address these challenges by establishing coordinated efforts to improve Blue Economy research in these regions, enhancing funding for innovative research, and strengthening partnerships across sectors to build a Blue Economy research network. This project will bring together students, faculty, and researchers from U.S. institutions, along with participants from broad fields, including GIScience, oceanography, computer science, biology, and civil engineering. The goal is to promote AI education and workforce development in Blue Economy research. Nowadays, AI has transformative potential to enhance blue economy research by providing advanced tools for data analysis, modeling, and decision-making.","The workshop will offer training opportunities to help research communities effectively navigate NAIRR pilot resources, including learning how to access and use these resources for ocean and coastal sustainability analysis. All workshop and training materials will be made publicly available through a project GitHub repository and website, ensuring broad accessibility and ongoing learning opportunities. Participants will learn skills of cyberinfrastructure and high-performance computing, oceanography, disaster management, and coastal resilience planning.",,Utilizing NAIRR Pilot Resources for Building Sustainable Blue Economy,"NAIRR, Cyberinfrastructure, Blue Economy, Artificial Intelligence, Oceanography, GIScience","Dr. Zhe Zhang is an Associate Professor in the Department of Geography at Texas A&M University. Dr. Zhang has served as Chair of the Cyberinfrastructure Specialty Group of the American Association of Geographers and was elected to the Board of Directors of the Cartography and Geographic Information Society. She also serves as Chair of the Research Committee of the University Consortium for Geographic Information Science. Her research focuses on developing spatial decision support systems by integrating advanced cyberinfrastructure, geospatial artificial intelligence, and participatory design to address critical challenges in disaster management and sustainability. Dr. Zhang serves as the Co-Principal Investigator of the Texas A&M FASTER High-Performance Supercomputer (over $3 million) and as a Co-Investigator of the Texas A&M ACES Supercomputer (over $12 million), both supported by the NSF. In addition, she serves as Principal Investigator on eight externally funded grants from (NSF, NASA, USDOT, NOAA, and National Geographic Society), totaling over $3 million. Dr. Zhang has been honored to receive both the Pathways Award from Texas A&M Faculty Affairs and the National Science Foundation CAREER Award in recognition of her impactful research."
proj143s1,Accept Wave 2 (Confirmed),Avi,Sahu,asahu@salud.unm.edu,UNM Comprehensive Cancer Center,Dept of Internal Medicine,png Information Type: pngSize: 1MBUploaded: Oct 10MD5: baa1c5fc89eaf1d6812fa40777e88ce6Original Name: headshot.png view move to AWS,https://www.tumorai.org,Bridging Molecules and Medicine: Explainable AI for Genetics and Imaging,Advancing Colorectal Cancer Diagnosis: A Multimodal AI Copilot for Real-Time Endoscopy,,Artificial Intelligence and Intelligent Systems; Biochemistry and Molecular Biology; Clinical Medicine; Health Sciences,"Millions of people face deep uncertainty in their fight against cancer. Two major hurdles often stand in the way of clear answers. First, genetic testing frequently returns ambiguous results called ""variants of unknown significance"" (VUS), leaving nearly 40% of patients in an anxious ""diagnostic limbo"" without clear medical guidance. Second, a nationwide shortage of specialists means that interpreting crucial medical images, like endoscopies, can be slow and inconsistent, delaying life-saving diagnoses. 🩺 Our lab is pioneering a solution by building AI ""co-pilots"" for medicine. We have already developed the core technology: powerful AI models that can translate complex genetic data (Protein2Text) and interpret endoscopic images (EndoPilot). This project will focus on the most exciting application of these powerful tools. We will create Mutation2Text to demystify VUS with clear, understandable rationales. Concurrently, we will build MED-X, a framework where a team of our AIs work together (AI agents) to help doctors spot signs of colorectal cancer with greater accuracy. This project will deliver a unified pipeline that empowers clinicians, provides clear answers to patients, and makes expert-level care accessible to all.","We are building a diverse team and welcome collaborators from all backgrounds. Whether you are a coder, biologist, future doctor, or creative problem-solver, there is a place for you. We seek faculty/students with interests in: Technology & Data Science: Help build and train cutting-edge AI models using skills like Python and machine learning. Biology & Health Sciences: Use your background in genetics or life sciences to guide our AI’s reasoning and ensure its insights are clinically useful. Human-Centered Thinking: Help us create trustworthy, explainable AI that doctors can confidently use to improve patient care.",,Explainable AI Co‑Pilots for Genes and Endoscopy,Explainable AI; Genomics; Variant interpretation; Endoscopy; Multimodal LLMs; Human‑AI collaboration; Cancer prevention; Precision oncology; Ovarian cancer; Colorectal cancer.,"Avinash (“Avi”) Das Sahu, PhD is an assistant professor at UNM Comprehensive Cancer Center and Dept of Computer Science, where he leads th TumorAI lab (Tumorai.org). His group designs interpretable, clinician ready AI that links molecular signals to real world decisions in cancer care. The group builds AI “co pilots” across two fronts: (1) genomics, including Protein2Text and the forthcoming Mutation2Text to explain variants—especially VUS—with clear, rationale based text; and (2) medical imaging, where EndoPilot and the multi agent MED X framework support transparent, human in the loop analysis of endoscopic images for colorectal cancer. Guided by a simple aim—to “prevent the preventable and treat the treatable”— he collaborates closely with oncologists and geneticists to move these tools from algorithms to clinic ready prototypes. His work has been recognized with awards such as the OCRA CDRG (PI), NIH Pathway to Independence (K99/R00), and the Michelson Prize, following training at the University of Maryland/NHGRI and postdoctoral work at Dana Farber/Harvard and the Broad Institute. Beyond publishing in venues such as Cancer Discovery and Nature Communications, his lab emphasizes open science, inclusive mentoring, and deployment on high performance computing resources to broaden access to expert level decision."
proj144s1,Accept Wave 2 (Confirmed),Tuan,Do,tdo@astro.ucla.edu,UCLA,,jpg Information Type: jpgSize: 412KBUploaded: Oct 10MD5: 2ccc4331181e6d01ec92e4f2e1cc8b52Original Name: Tuan_Do_P8300064r... view move to AWS,https://datalab.astro.ucla.edu/,Integrating LLMs into Machine Learning for Physics and Astronomy Education,Improving Access to Computation for Machine Learning for Physical Sciences Course,,Artificial Intelligence and Intelligent Systems; Astronomy and Planetary Sciences; Particle and High-Energy Physics,"This project is to study how to use large language models (LLMs) and related technologies into a course on Machine Learning for Physical Sciences at the upper division undergraduate level. LLMs are now a prominent technology in computer science and the industry, and many students have experience using them. However, students do not typically get the opportunity to setup their own LLM and do experiments on them. Specifically, the use of LLMs in scientific education is not well explored. This project aims to develop a course unit on both using existing LLMs as well as the underlying LLM architectures (e.g. transformers) for science. Potential projects include setting up and deploying local LLMs and examining their abilities to do physics research. Another is to combine images and text from astrophysics into a transformer to use data fusion for classification. By giving students experience in underlying technologies behind these tools, they will become more knowledgeable and responsible users of AI and develop skills useful for their careers.","Background in teaching, designing lab courses, and/or deploying large language models.",,Developing an LLM curriculum for AI/ML in Physical Sciences courses,LLMs; transformers; science education; Physical Sciences; Physics; Astrophysics; Data Science; Lab Classes,Tuan Do is an Associate Professor at UCLA in the Physics and Astronomy Department. He is the PI of the UCLA Astrophysics Data Lab. He got his undergraduate degrees in Physics and Astrophysics from UC Berkeley and his Astrophysics Ph.D. at UCLA. His research focuses on translating ML/AI models for Astrophysics applications. He created the first Machine Learning for Physical Science course at UCLA.
proj146s1,Accept Wave 2 (Confirmed),Haohan,Wang,haohanw@illinois.edu,University of Illinois Urbana Champaign,School of Information Sciences,jpg Information Type: jpgSize: 2MBUploaded: Oct 10MD5: bcb77a700a959547b7266fb7e6ca282fOriginal Name: haohanwang.jpg view move to AWS,https://haohanwang.github.io/,Toward Redefining Disease Taxonomy: Scaling Transcriptomic Analysis with Agentic AI Systems,Toward Redefining Disease Taxonomy: Scaling Transcriptomic Analysis with Agentic AI Systems,,Basic Medicine; Biochemistry and Molecular Biology; Health Sciences,"The project aims to redefine how diseases are classified by using agentic artificial intelligence—a new generation of self-revising, collaborative AI systems—to analyze large-scale human transcriptomic data. Today’s biomedical research relies on rigid pipelines that struggle to integrate data across tissues, populations, and rare conditions. We will build an AI framework composed of autonomous reasoning agents that continuously analyze and validate public datasets, learning to correct themselves and adapt to missing metadata or unexpected patterns. These agents will uncover disease relationships directly from molecular signals rather than from pre-defined diagnostic categories. The outcome is a data-driven taxonomy of disease—linking common and rare conditions through shared regulatory signatures—that could reshape how medicine understands biological variability. Students will join a cross-disciplinary team at the intersection of AI, computational biology, and open science, contributing to a system that learns science itself.","We welcome students from computer science, data science, biology, or related fields who are curious about how AI can advance scientific discovery. Interest in coding, statistics, or genomics is helpful but not required. The most important traits are curiosity, persistence, and comfort working across disciplines. Experience with Python, R, or machine learning frameworks is a plus, but students can learn these skills during the project.","Students will gain experience working with large biological datasets and intelligent systems that operate autonomously. The environment emphasizes mentorship, open collaboration, and publication-quality research. Outstanding participants may continue with the lab through independent study or joint conference submissions.",Toward Redefining Disease Taxonomy,"Disease should not be defined by clinical manifestation, but by the underlying mechanism","Haohan Wang is an assistant professor in the School of Information Sciences at the University of Illinois Urbana-Champaign. His research focuses on the development of trustworthy machine learning methods for computational biology and healthcare applications, such as decoding the genomic language of Alzheimer's disease. In his work, he uses statistical analysis and deep learning methods, with an emphasis on data analysis using methods least influenced by spurious signals. Wang earned his PhD in computer science through the Language Technologies Institute of Carnegie Mellon University where he works with Professor Eric Xing. In 2019, Wang was recognized as the Next Generation in Biomedicine by the Broad Institute of MIT and Harvard because of his contributions in dealing with confounding factors with deep learning."
proj148s1,Accept Wave 2 (Unconfirmed),Yizhou,Sun,yzsun@cs.ucla.edu,UCLA,CS,,https://web.cs.ucla.edu/~yzsun/,Navigating Chemical Reaction Space via Deep Learning,NAIRR Pilot Project — Navigating Chemical Reaction Space via Deep Learning,,Applied Computer Science; Applied Mathematics; Artificial Intelligence and Intelligent Systems; Biochemistry and Molecular Biology; Chemical Engineering; Materials Engineering,"Chemical reactions power everything from new medicines to sustainable materials—but predicting how molecules transform under different conditions is still hard. Our project builds AI models that “learn” reaction behavior from data, aiming to (1) capture how 3D molecular structures evolve from reactants through high-energy transition states to products, (2) predict outcomes of individual reactions by combining 3D molecular information with experimental steps, and (3) plan multi-step synthetic routes with interpretable reasoning. Students and faculty will help develop and evaluate deep learning systems (e.g., graph neural networks, diffusion models, and language-model–based planners), curate datasets, and test ideas on open benchmarks. This work blends modern AI with chemistry and has direct impact on faster drug discovery, greener catalysis, and more efficient materials design. The summer experience can be tailored to backgrounds ranging from applied ML to computational chemistry, with mentored sub-projects that emphasize scientific rigor, reproducibility, and open research practices.","-Strong programming in Python; experience with PyTorch/JAX or similar DL frameworks -Interest or experience in at least one: deep learning for molecules (GNNs, diffusion, transformers), NLP/RAG for scientific text, or computational chemistry (e.g., DFT, reaction mechanisms, conformations) -Familiarity with scientific Python stack (NumPy, pandas), version control (Git), and good experiment hygiene (reproducible runs, logging) -Nice-to-have: RDKit/cheminformatics; 3D geometry; thermodynamics/kinetics basics; HPC or multi-GPU training -We especially welcome advanced undergraduates and graduate students who have prior research experience in deep learning or computational chemistry and are excited about interdisciplinary collaboration","-Mentoring & pairing: We will pair each participant with a UCLA CS PhD mentor; weekly 1:1s and group meetings ensure steady progress. -Project tracks: (A) 3D reaction dynamics modeling, (B) reaction-outcome prediction with multimodal inputs, (C) multi-step retrosynthesis with retrieval-augmented reasoning. -Deliverables: Open-source code with reproducible scripts; a short workshop paper or poster; optional preprint if results warrant. - Onsite details: Summer 2026 at UCLA (Los Angeles, CA). Start/end dates flexible within SRP windows. - Accessibility: Projects can be adjusted to fit primarily-ML or primarily-chemistry backgrounds while keeping a strong collaboration core",,,
proj149s1,Accept Wave 2 (Confirmed),Steven,Fernandes,stevenfernandes@creighton.edu,Creighton University,"Computer Science, Design and Journalism",jpg Information Type: jpgSize: 5MBUploaded: Oct 15MD5: 10265fc9952999fb714e9630a89d5355Original Name: Steven_Fernandes.jpg view move to AWS,https://www.creighton.edu/campus-directory/fernandes-steven-l,Building Generative AI Applications,CSC 590 - Building Generative AI Applications,,Artificial Intelligence and Intelligent Systems; Computer Science; Health Sciences; Software Engineering,"This project explores how to build artificial intelligence systems that can create, understand, and assist with real-world tasks. We'll work on three exciting types of applications. First, we'll create an AI that can generate new content, such as images. This has applications everywhere from art and entertainment to marketing and product design. Second, we'll build AI that can search through large collections of information and provide accurate, helpful answers by combining what it finds with its ability to generate responses. Think of this as creating smarter search tools or assistants that can actually comprehend documents and assist people in making informed decisions. Third, we'll develop autonomous AI agents that can complete multi-step tasks independently, like digital assistants that handle scheduling, research, or workflow automation. This work matters because these technologies are transforming every industry from healthcare to education to creative fields. Understanding how to build them responsibly puts you at the forefront of real innovation. We welcome collaborators from all backgrounds and experience levels, whether you're interested in coding, design, ethics, user experience, or simply curious about what AI can do. You'll gain practical hands-on skills while working on applications that could genuinely help people in their everyday lives.","We welcome collaborators from diverse backgrounds and with varying experience levels. Helpful skills include basic programming in any language, an interest in how AI systems work, or experience with data and information. Creative thinking, problem solving, user experience design, and perspectives on ethics or responsible AI development are all valuable. Most importantly, we're looking for curiosity, willingness to learn, and enthusiasm for exploring how these technologies can solve real problems.","If possible, I would be interested in considering the following two students from Creighton University: (1) Our PhD student, Vignesh Rathinavelpandian Anandavel, applied for the student track and was also included in my initial faculty track application. (2) The undergraduate student, Sara Avila, was only included as a student in my initial faculty track application.",Generative AI for Cochlear Hair Cell Detection,Generative AI; Deep Learning; Computer Vision; Machine Learning; Medical Image Processing.,"I am an Assistant Professor of Computer Science at Creighton University, where I have taught and mentored students in computer science, data science, and health informatics since joining in July 2020. My research focuses on developing advanced deep learning models for applications in computer vision, medical imaging, and natural language processing. Before my current role, I completed postdoctoral research in the Department of Computer Science at the University of Central Florida from September 2018 to June 2020, contributing to projects funded by the Defense Advanced Research Projects Agency (DARPA), National Science Foundation (NSF), and Royal Bank of Canada (RBC), with a focus on deep learning and computer vision. Additionally, I conducted postdoctoral research in the Department of Electrical and Computer Engineering at the University of Alabama at Birmingham from July 2017 to August 2018, working on National Institutes of Health (NIH)-funded projects related to deep learning and medical image processing. My research has obtained compute credits through NAIRR Pilot Classroom, NAIRR Startup, Amazon Web Services, and Google Cloud Platform. I have published articles in high-impact AI venues, including NeurIPS, CVPR, ECCV, and ICCV."
proj150s1,Accept (Unconfirmed),Axel,Huebl,axelhuebl@lbl.gov,Lawrence Berkeley National Laboratory,Accelerator Technology & Applied Physics,jpg Information Type: jpgSize: 227KBUploaded: Oct 19MD5: cb9acf1f3bdb4b05b9c432931341da3cOriginal Name: Axel_Huebl.jpg view move to AWS,https://github.com/ax3l/,Novel Exascale & AI Workflows with WarpX,,WarpX,Applied Computer Science; Applied Mathematics; Fluid and Plasma Physics; High Performance Computing; Open Source Software; Particle and High-Energy Physics; Performance Evaluation and Benchmarking; Software Engineering,"We are envisioning several projects that involve improving and expanding the performance or scientific workflows using WarpX, including: 1. Parallel data post-processing with DASK and openPMD. 2. Automatic differentiation of C++ simulations through tools like Enzyme. 3. Implementation of numerical algorithms for the modeling of plasmas, lasers, and particle beams, with applications in fusion and/or accelerator physics. 4. Training fast AI/ML surrogate models. Incorporate those into simulations, integrated research infrastructures, updating models in real-time from experimental and simulation data as they become available, and/or informing operation in experiments. The above implementations and workflows will be demonstrated on and evaluated with WarpX simulations in fusion and particle accelerator physics.","We are looking for people interested in developing new code (C++, Python), implement numerics, or new workflows to address timely challenges in fusion and particle accelerator science. Ideally, you already have experience with C++, Python and Git/GitHub and are eager to be embedded in an open, interdisciplinary team.",,,,
