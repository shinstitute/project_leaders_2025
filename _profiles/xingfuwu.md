---
layout: profile
name: Xingfu Wu
organization: Argonne National Laboratory
title: Autotuning Scientific Applications at Scale
topics: Computer Science (i.e., architectures, compilers/languages, networks, workflow/edge,
  experiment automation, containers, neuromorphic computing, programming models, operating
  systems, sustainable software); High-Performance Computing; Machine Learning and
  AI
abstract: As we enter the exascale computing era, efficiently utilizing power and
  optimizing the performance of scientific software under power and energy constraints
  are challenging. Scientific software developers often rely on HPC systems with the
  default configurations setup by the vendors to run their applications, however,
  their applications are not efficiently executed with the default system configurations.
  The number of tunable parameters that HPC users can configure at the system and
  software levels has increased significantly because of the complexity of the HPC
  ecosystems, resulting in a dramatically increased parameter space. Attempting to
  evaluate many (or all) possible parameter combinations becomes very time-consuming.
  Therefore, scientific application developers will be able to use our publicly available
  autotuning software package ytopt (https://github.com/ytopt-team/ytopt) to autotune
  their applications on the target HPC systems to identify the best configuration
  (for software and system parameters) and then use the best configuration to run
  their applications efficiently on the target systems. This approach not only optimizes
  scientific software for efficient execution and energy efficiency but also saves
  considerable energy on exascale supercomputers at DOE leadership computing facilities.
---

## Additional Information

Add additional details about Xingfu_Wu here using markdown.

### Skills & Expertise

- Add relevant skills
- Add areas of expertise
- Add specializations

### Recent Work

Describe recent projects, publications, or achievements.
